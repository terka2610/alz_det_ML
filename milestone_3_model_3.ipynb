{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O4Yf-IoK0js"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets in /ext3/miniconda3/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /ext3/miniconda3/lib/python3.12/site-packages (from PyWavelets) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /ext3/miniconda3/lib/python3.12/site-packages (1.9.0)\n",
      "Requirement already satisfied: decorator in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (3.10.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (2.1.3)\n",
      "Requirement already satisfied: packaging in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (24.2)\n",
      "Requirement already satisfied: pooch>=1.5 in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (1.15.2)\n",
      "Requirement already satisfied: tqdm in /ext3/miniconda3/lib/python3.12/site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /ext3/miniconda3/lib/python3.12/site-packages (from pooch>=1.5->mne) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /ext3/miniconda3/lib/python3.12/site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /ext3/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ext3/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ext3/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /ext3/miniconda3/lib/python3.12/site-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.11.4 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (1.15.2)\n",
      "Requirement already satisfied: networkx>=3.0 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (3.4.2)\n",
      "Requirement already satisfied: pillow>=10.1 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (11.1.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (2025.3.13)\n",
      "Requirement already satisfied: packaging>=21 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /ext3/miniconda3/lib/python3.12/site-packages (from scikit-image) (0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kqS6KVS9K0jo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import mne\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time # To measure time\n",
    "\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import detrend, butter, filtfilt\n",
    "import pywt\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_float, img_as_ubyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_eeg_data(folder_path):\n",
    "    data = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".set\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            raw = mne.io.read_raw_eeglab(file_path, preload=True)\n",
    "            data[filename] = raw.get_data()\n",
    "    return data\n",
    "\n",
    "def read_json_dicts(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data_dict = json.load(f)\n",
    "    return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xH5v5FIEK0jt"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eegnet_minimal(eeg_data, fs, lowcut=1.0, highcut=40.0, order=5):\n",
    "    \"\"\"\n",
    "    Applies minimal preprocessing suitable for models like EEGNet:\n",
    "    Bandpass filtering and channel-wise standardization.\n",
    "\n",
    "    Args:\n",
    "        eeg_data (np.ndarray): Raw EEG data (n_channels, n_timesteps).\n",
    "        fs (float): Original sampling frequency.\n",
    "        lowcut (float): Lower cutoff frequency for bandpass filter (Hz).\n",
    "        highcut (float): Upper cutoff frequency for bandpass filter (Hz).\n",
    "        order (int): Order of the Butterworth filter.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed EEG data (n_channels, n_timesteps).\n",
    "    \"\"\"\n",
    "    n_channels, n_timesteps = eeg_data.shape\n",
    "    processed_data = np.zeros_like(eeg_data)\n",
    "\n",
    "    # 1. Bandpass Filter Design\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    # Ensure frequency bounds are valid\n",
    "    if low <= 0 or high >= 1:\n",
    "         print(f\"Warning: Filter frequencies ({lowcut}Hz, {highcut}Hz) are invalid for Nyquist freq {nyq}Hz. Adjusting or skipping filter.\")\n",
    "         # Option: Skip filtering or adjust bounds\n",
    "         b, a = None, None # Indicate filter skip\n",
    "    else:\n",
    "        try:\n",
    "            b, a = butter(order, [low, high], btype='band')\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not design Butterworth filter (order={order}, freqs=[{low}, {high}]). Skipping filter. Error: {e}\")\n",
    "            b, a = None, None\n",
    "\n",
    "\n",
    "    # 2. Apply Filter and Standardize Channel by Channel\n",
    "    for i_ch in range(n_channels):\n",
    "        channel_data = eeg_data[i_ch, :]\n",
    "\n",
    "        # Apply filtering if filter design was successful\n",
    "        if b is not None and a is not None:\n",
    "             try:\n",
    "                 filtered_data = filtfilt(b, a, channel_data)\n",
    "             except Exception as e:\n",
    "                 print(f\"Warning: Filtering failed for channel {i_ch}. Using original data for this channel. Error: {e}\")\n",
    "                 filtered_data = channel_data # Use original if filtering fails\n",
    "        else:\n",
    "             filtered_data = channel_data # Use original if filter wasn't designed\n",
    "\n",
    "        # Standardize (z-score normalization)\n",
    "        mean = np.mean(filtered_data)\n",
    "        std = np.std(filtered_data)\n",
    "        if std > 1e-9: # Avoid division by zero\n",
    "            processed_data[i_ch, :] = (filtered_data - mean) / std\n",
    "        else:\n",
    "            processed_data[i_ch, :] = filtered_data - mean # Only center if std is zero\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "aYbQDIy8K0ju"
   },
   "outputs": [],
   "source": [
    "def calculate_td_psd_features(epoch_data, fs, power_lambda=0.1, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Calculates the 7 TD-PSD features for a single EEG epoch (single channel).\n",
    "    Based on equations in Amini et al., 2021.\n",
    "\n",
    "    Args:\n",
    "        epoch_data (np.ndarray): 1D numpy array for a single channel epoch.\n",
    "        fs (float): Sampling frequency of the epoch data.\n",
    "        power_lambda (float): Lambda for power transform normalization.\n",
    "        epsilon (float): Small value to prevent log(0) or division by zero.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array containing the 7 log-transformed TD-PSD features.\n",
    "                    Returns NaNs if calculation fails.\n",
    "    \"\"\"\n",
    "    n_samples = len(epoch_data)\n",
    "    if n_samples == 0:\n",
    "        return np.full(7, np.nan)\n",
    "\n",
    "    # Detrend the signal (optional but often good practice)\n",
    "    signal = detrend(epoch_data)\n",
    "\n",
    "    # 1. Calculate Power Spectrum and Moments\n",
    "    try:\n",
    "        # FFT\n",
    "        X = fft(signal)\n",
    "        # Power Spectrum (One-sided, ignoring DC for moments perhaps?)\n",
    "        # Frequencies for moments k: corresponds to frequency bins\n",
    "        freqs = np.fft.fftfreq(n_samples, 1/fs)\n",
    "        # Power spectrum P[k] = |X[k]|^2 / N\n",
    "        P = np.abs(X)**2 / n_samples\n",
    "\n",
    "        # Calculate moments m0, m2, m4\n",
    "        # m_n = sum(f^n * P(f)) df - approximated by sum(k^n * P[k])\n",
    "        # We use the magnitude of frequencies for k, ignore negative freqs?\n",
    "        # Let's use Hjorth parameters definition based on time-domain variance\n",
    "        # m0 = variance(signal) = total power (approx)\n",
    "        m0_bar = np.sum(signal**2) / n_samples # Variance = mean square if mean is zero\n",
    "        if m0_bar < epsilon: m0_bar = epsilon\n",
    "\n",
    "        # m2 = variance of first derivative (activity)\n",
    "        delta_x = np.diff(signal, n=1) * fs # Scale by fs? Hjorth doesn't explicitly scale by fs\n",
    "        m2_bar = np.sum(delta_x**2) / (n_samples -1) # Use n_samples-1?\n",
    "        if m2_bar < epsilon: m2_bar = epsilon\n",
    "\n",
    "\n",
    "        # m4 = variance of second derivative (mobility)\n",
    "        delta2_x = np.diff(signal, n=2) * (fs**2) # Scale by fs^2?\n",
    "        m4_bar = np.sum(delta2_x**2) / (n_samples -2)\n",
    "        if m4_bar < epsilon: m4_bar = epsilon\n",
    "\n",
    "\n",
    "        # Apply power transform (Box-Cox with lambda=0 is log, this is slightly different)\n",
    "        m0 = (m0_bar**power_lambda - 1) / power_lambda if power_lambda != 0 else np.log(m0_bar)\n",
    "        m2 = (m2_bar**power_lambda - 1) / power_lambda if power_lambda != 0 else np.log(m2_bar)\n",
    "        m4 = (m4_bar**power_lambda - 1) / power_lambda if power_lambda != 0 else np.log(m4_bar)\n",
    "\n",
    "        # Ensure moments are positive after transform for log\n",
    "        m0 = max(m0, epsilon)\n",
    "        m2 = max(m2, epsilon)\n",
    "        m4 = max(m4, epsilon)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating moments: {e}\")\n",
    "        return np.full(7, np.nan)\n",
    "\n",
    "    features = np.zeros(7)\n",
    "\n",
    "    # 2. Calculate Features f1, f2, f3\n",
    "    try:\n",
    "        features[0] = np.log(m0) # f1 = log(m0)\n",
    "        # Check for valid subtractions\n",
    "        if m0 <= m2: m0 = m2 + epsilon\n",
    "        if m0 <= m4: m0 = m4 + epsilon\n",
    "        features[1] = np.log(m0 - m2) # f2 = log(m0 - m2)\n",
    "        features[2] = np.log(m0 - m4) # f3 = log(m0 - m4)\n",
    "\n",
    "    except Exception as e:\n",
    "         print(f\"Error calculating f1, f2, f3: {e}\")\n",
    "         features[:3] = np.nan\n",
    "\n",
    "\n",
    "    # 3. Calculate Feature f4 (Sparseness)\n",
    "    try:\n",
    "        denominator_sqrt = np.sqrt(max(m0 - m2, epsilon)) * np.sqrt(max(m0 - m4, epsilon))\n",
    "        if denominator_sqrt < epsilon: denominator_sqrt = epsilon\n",
    "        features[3] = np.log(m0 / denominator_sqrt) # f4 = log(S) = log(m0 / sqrt((m0-m2)(m0-m4)))\n",
    "    except Exception as e:\n",
    "         print(f\"Error calculating f4 (Sparseness): {e}\")\n",
    "         features[3] = np.nan\n",
    "\n",
    "    # 4. Calculate Feature f5 (Irregularity Factor - IF)\n",
    "    # IF = (m4/m2) / (m2/m0) based on Hjorth parameters 'complexity'\n",
    "    # Paper formula: sqrt(m4/m2) / sqrt(m2/m0) => m0*m4 / m2^2\n",
    "    try:\n",
    "        if m2 < epsilon: m2 = epsilon\n",
    "        if_val = (m0 * m4) / (m2**2)\n",
    "        features[4] = np.log(max(if_val, epsilon)) # f5 = log(IF)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating f5 (IF): {e}\")\n",
    "        features[4] = np.nan\n",
    "\n",
    "    # 5. Calculate Feature f6 (Covariance - COV)\n",
    "    # COV = std_dev / mean\n",
    "    try:\n",
    "        mean_val = np.mean(signal)\n",
    "        std_dev_val = np.std(signal)\n",
    "        if abs(mean_val) < epsilon: mean_val = np.sign(mean_val) * epsilon if mean_val != 0 else epsilon\n",
    "        cov_val = std_dev_val / mean_val\n",
    "        features[5] = np.log(max(abs(cov_val), epsilon)) # Log of magnitude? Paper isn't explicit if COV can be negative. Let's take abs.\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating f6 (COV): {e}\")\n",
    "        features[5] = np.nan\n",
    "\n",
    "\n",
    "    # 6. Calculate Feature f7 (Teager Energy Operator - TEO)\n",
    "    try:\n",
    "        # TEO(x[j]) = x[j]^2 - x[j-1]x[j+1]\n",
    "        # Need to handle boundaries (pad or slice)\n",
    "        teo_vals = signal[1:-1]**2 - signal[:-2] * signal[2:]\n",
    "        sum_teo = np.sum(teo_vals)\n",
    "        features[6] = np.log(max(abs(sum_teo), epsilon)) # Log of magnitude? Sum can be negative. Paper isn't explicit. Taking abs.\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating f7 (TEO): {e}\")\n",
    "        features[6] = np.nan\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_eegnet_minimal(eeg_data, fs, lowcut=1.0, highcut=40.0, order=5):\n",
    "    \"\"\"\n",
    "    Applies minimal preprocessing suitable for models like EEGNet:\n",
    "    Bandpass filtering and channel-wise standardization.\n",
    "\n",
    "    Args:\n",
    "        eeg_data (np.ndarray): Raw EEG data (n_channels, n_timesteps).\n",
    "        fs (float): Original sampling frequency.\n",
    "        lowcut (float): Lower cutoff frequency for bandpass filter (Hz).\n",
    "        highcut (float): Upper cutoff frequency for bandpass filter (Hz).\n",
    "        order (int): Order of the Butterworth filter.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed EEG data (n_channels, n_timesteps).\n",
    "    \"\"\"\n",
    "    n_channels, n_timesteps = eeg_data.shape\n",
    "    processed_data = np.zeros_like(eeg_data)\n",
    "\n",
    "    # 1. Bandpass Filter Design\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    # Ensure frequency bounds are valid\n",
    "    if low <= 0 or high >= 1:\n",
    "         print(f\"Warning: Filter frequencies ({lowcut}Hz, {highcut}Hz) are invalid for Nyquist freq {nyq}Hz. Adjusting or skipping filter.\")\n",
    "         # Option: Skip filtering or adjust bounds\n",
    "         b, a = None, None # Indicate filter skip\n",
    "    else:\n",
    "        try:\n",
    "            b, a = butter(order, [low, high], btype='band')\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not design Butterworth filter (order={order}, freqs=[{low}, {high}]). Skipping filter. Error: {e}\")\n",
    "            b, a = None, None\n",
    "\n",
    "\n",
    "    # 2. Apply Filter and Standardize Channel by Channel\n",
    "    for i_ch in range(n_channels):\n",
    "        channel_data = eeg_data[i_ch, :]\n",
    "\n",
    "        # Apply filtering if filter design was successful\n",
    "        if b is not None and a is not None:\n",
    "             try:\n",
    "                 filtered_data = filtfilt(b, a, channel_data)\n",
    "             except Exception as e:\n",
    "                 print(f\"Warning: Filtering failed for channel {i_ch}. Using original data for this channel. Error: {e}\")\n",
    "                 filtered_data = channel_data # Use original if filtering fails\n",
    "        else:\n",
    "             filtered_data = channel_data # Use original if filter wasn't designed\n",
    "\n",
    "        # Standardize (z-score normalization)\n",
    "        mean = np.mean(filtered_data)\n",
    "        std = np.std(filtered_data)\n",
    "        if std > 1e-9: # Avoid division by zero\n",
    "            processed_data[i_ch, :] = (filtered_data - mean) / std\n",
    "        else:\n",
    "            processed_data[i_ch, :] = filtered_data - mean # Only center if std is zero\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc1xIGdpK0jw"
   },
   "source": [
    "£Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "j5AixcgkscKr"
   },
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    EEGNet: compact CNN architecture for EEG-based BCIs.\n",
    "    \n",
    "    Implementation based on Lawhern et al. (2018):\n",
    "    \"EEGNet: A Compact Convolutional Neural Network for EEG-based Brain-Computer Interfaces\"\n",
    "    \n",
    "    Args:\n",
    "        n_channels (int): Number of EEG channels\n",
    "        n_timesteps (int): Number of timesteps in the EEG signal\n",
    "        num_classes (int): Number of output classes\n",
    "        dropout_rate (float): Dropout probability\n",
    "        F1 (int): Number of temporal filters\n",
    "        D (int): Depth multiplier\n",
    "        F2 (int): Number of pointwise filters\n",
    "        kernel_length (int): Length of temporal kernel\n",
    "        normalize (bool): Whether to use batch normalization\n",
    "    \"\"\"\n",
    "    def __init__(self, n_channels, n_timesteps, num_classes, dropout_rate=0.5, \n",
    "                 F1=8, D=2, F2=16, kernel_length=64, normalize=True):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.num_classes = num_classes\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        # Block 1: Temporal Convolution and Depthwise Spatial Convolution\n",
    "        self.block1 = nn.Sequential(\n",
    "            # Temporal Convolution\n",
    "            nn.Conv2d(1, F1, kernel_size=(1, kernel_length), padding=(0, kernel_length//2), bias=False),\n",
    "            nn.BatchNorm2d(F1) if normalize else nn.Identity(),\n",
    "            \n",
    "            # Depthwise Spatial Convolution\n",
    "            nn.Conv2d(F1, F1 * D, kernel_size=(n_channels, 1), groups=F1, bias=False),\n",
    "            nn.BatchNorm2d(F1 * D) if normalize else nn.Identity(),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 4)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Block 2: Separable Convolution\n",
    "        # Separable convolution consists of a depthwise temporal convolution followed by a pointwise convolution\n",
    "        self.block2 = nn.Sequential(\n",
    "            # Depthwise Temporal Convolution \n",
    "            nn.Conv2d(F1 * D, F1 * D, kernel_size=(1, 16), padding=(0, 8), groups=F1 * D, bias=False),\n",
    "            nn.BatchNorm2d(F1 * D) if normalize else nn.Identity(),\n",
    "            \n",
    "            # Pointwise Convolution\n",
    "            nn.Conv2d(F1 * D, F2, kernel_size=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(F2) if normalize else nn.Identity(),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Calculate output feature size for the FC layer\n",
    "        # after temporal convolution: n_timesteps (no change due to padding)\n",
    "        # after first pooling: n_timesteps/4\n",
    "        # after second pooling: n_timesteps/32\n",
    "        self.out_features = F2 * (n_timesteps // 32)\n",
    "        \n",
    "        # Classification layer\n",
    "        self.classifier = nn.Linear(self.out_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, n_channels, n_timesteps)\n",
    "        # Reshape for 2D convolution\n",
    "        x = x.unsqueeze(1)  # (batch_size, 1, n_channels, n_timesteps)\n",
    "        \n",
    "        # Apply blocks\n",
    "        x = self.block1(x)  # (batch_size, F1*D, 1, n_timesteps/4)\n",
    "        x = self.block2(x)  # (batch_size, F2, 1, n_timesteps/32)\n",
    "        \n",
    "        # Flatten for FC layer\n",
    "        x = x.view(x.size(0), -1)  # (batch_size, F2 * (n_timesteps/32))\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)  # (batch_size, num_classes)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Define the class weights before using them in the function definition\n",
    "default_class_weight = {\n",
    "    0: 0.7941,   # A\n",
    "    1: 0.8360,   # C\n",
    "    2: 1.8364    # F\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_LE7IO3K0jy"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dqR8q61MK0jy"
   },
   "outputs": [],
   "source": [
    "# --- Modified Generic Training Function with Validation ---\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Generic function to train and validate a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader or None): DataLoader for the validation data. If None, validation is skipped.\n",
    "        criterion (nn.Module): The loss function (e.g., nn.CrossEntropyLoss).\n",
    "        optimizer (Optimizer): The optimizer (e.g., optim.Adam).\n",
    "        num_epochs (int): Number of epochs to train for.\n",
    "        device (torch.device): The device to train on (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "        None: Prints training and validation progress information directly.\n",
    "    \"\"\"\n",
    "    model.to(device) # Move model to the designated device\n",
    "    total_train_steps = len(train_loader)\n",
    "    if val_loader:\n",
    "        total_val_steps = len(val_loader)\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"\\n--- Training {model.__class__.__name__} ---\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training Phase ---\n",
    "        model.train() # Set the model to training mode\n",
    "        epoch_train_loss = 0.0\n",
    "        train_correct_predictions = 0\n",
    "        train_total_samples = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Move data to the designated device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate training statistics\n",
    "            epoch_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total_samples += labels.size(0)\n",
    "            train_correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate average training loss and accuracy for the epoch\n",
    "        avg_epoch_train_loss = epoch_train_loss / total_train_steps\n",
    "        epoch_train_accuracy = 100 * train_correct_predictions / train_total_samples\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        if val_loader is not None:\n",
    "            model.eval() # Set the model to evaluation mode\n",
    "            epoch_val_loss = 0.0\n",
    "            val_correct_predictions = 0\n",
    "            val_total_samples = 0\n",
    "\n",
    "            with torch.no_grad(): # Disable gradient calculations during validation\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    # Move data to the designated device\n",
    "                    val_inputs = val_inputs.to(device)\n",
    "                    val_labels = val_labels.to(device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss_batch = criterion(val_outputs, val_labels)\n",
    "\n",
    "                    # Accumulate validation statistics\n",
    "                    epoch_val_loss += val_loss_batch.item()\n",
    "                    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                    val_total_samples += val_labels.size(0)\n",
    "                    val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "            # Calculate average validation loss and accuracy for the epoch\n",
    "            avg_epoch_val_loss = epoch_val_loss / total_val_steps\n",
    "            epoch_val_accuracy = 100 * val_correct_predictions / val_total_samples\n",
    "\n",
    "            # Print combined epoch results\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {avg_epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.2f}%, '\n",
    "                  f'Val Loss: {avg_epoch_val_loss:.4f}, Val Acc: {epoch_val_accuracy:.2f}%')\n",
    "        else:\n",
    "            # Print only training results if no validation loader is provided\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {avg_epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.2f}%')\n",
    "\n",
    "        # Note: model is already set back to train() mode at the start of the next epoch loop iteration\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Training {model.__class__.__name__}. Total time: {end_time - start_time:.2f} seconds\")\n",
    "    # --- Consider saving the best model based on validation performance ---\n",
    "    # (Logic for tracking best val_accuracy/lowest val_loss and saving model state_dict would go here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_compare_models(models, model_names, data_loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    Evaluate multiple trained models on the same dataset and plot ROC curves.\n",
    "\n",
    "    Args:\n",
    "        models (list): List of trained PyTorch models.\n",
    "        model_names (list): List of model names for labeling.\n",
    "        data_loader (DataLoader): DataLoader for validation or test set.\n",
    "        device (torch.device): Device for model execution.\n",
    "        num_classes (int): Total number of output classes.\n",
    "\n",
    "    Returns:\n",
    "        reports (dict): A dictionary of classification report DataFrames per model.\n",
    "    \"\"\"\n",
    "    reports = {}\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        if data_loader is None:\n",
    "            print(f\"Skipping {name}: data_loader is None.\")\n",
    "            continue\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in data_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "                y_probs.extend(probs)\n",
    "                y_true.extend(y_batch.numpy())\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Print Accuracy\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"Accuracy: {acc:.2f}%\")\n",
    "\n",
    "        # Print classification report\n",
    "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        display(report_df[[\"precision\", \"recall\", \"f1-score\", \"support\"]])\n",
    "        reports[name] = report_df\n",
    "\n",
    "        # Compute ROC Curve (Micro-average for multiclass)\n",
    "        y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "        y_probs = np.array(y_probs)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin.ravel(), y_probs.ravel())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    # ROC Plot settings\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "    plt.title(\"Micro-Averaged ROC Curves\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z84oEIa-K0jz"
   },
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7GAKWO3K0jz"
   },
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MY7y9L_fmViM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/tj2286/alz_det_ML/model-data/fixed_data_aug\n",
      "Test folder exists: True\n",
      "Train folder exists: True\n",
      "Val folder exists: True\n",
      "Labels file exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths - everything is in the same directory\n",
    "folder_path_test = 'test'\n",
    "folder_path_train = 'train'\n",
    "folder_path_val = 'validate'\n",
    "file_path_labels = 'labels.json'\n",
    "\n",
    "# Load test data and labels\n",
    "data_val = collect_eeg_data(folder_path_val)\n",
    "data_test = collect_eeg_data(folder_path_test)\n",
    "data_train = collect_eeg_data(folder_path_train)\n",
    "data_labels = read_json_dicts(file_path_labels)\n",
    "\n",
    "# Optional debugging to verify paths\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Test folder exists: {os.path.exists(folder_path_test)}\")\n",
    "print(f\"Train folder exists: {os.path.exists(folder_path_train)}\")\n",
    "print(f\"Val folder exists: {os.path.exists(folder_path_val)}\")\n",
    "print(f\"Labels file exists: {os.path.exists(file_path_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gE0CFDcOK0j0"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we match the labels with the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Strip 'test/' or 'train/' prefix from data_labels.file_name\n",
    "data_labels['file_name'] = data_labels['file_name'].str.replace(r'^(test/|train/)', '', regex=True)\n",
    "\n",
    "# Build a mapping from base filename → label\n",
    "label_map = dict(zip(data_labels['file_name'], data_labels['label']))\n",
    "\n",
    "# 2. Create y_val and filter data_val\n",
    "y_val = {}\n",
    "for fn in list(data_val.keys()):\n",
    "    if fn in label_map:\n",
    "        y_val[fn] = label_map[fn]\n",
    "# keep only matched entries in data_val\n",
    "data_val = {fn: data_val[fn] for fn in y_val}\n",
    "\n",
    "# 3. Create y_test and filter data_test\n",
    "y_test = {}\n",
    "for fn in list(data_test.keys()):\n",
    "    if fn in label_map:\n",
    "        y_test[fn] = label_map[fn]\n",
    "data_test = {fn: data_test[fn] for fn in y_test}\n",
    "\n",
    "# 4. Create y_train and filter data_train, handling augmented filenames\n",
    "def get_base_filename(fn: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove augmentation suffix (_amplitude_scale, _noise, _time_shift) before '.set'.\n",
    "    E.g. 'sub-002_eeg_chunk_0_noise.set' → 'sub-002_eeg_chunk_0.set'\n",
    "    \"\"\"\n",
    "    return re.sub(r'_(amplitude_scale|noise|time_shift)(?=\\.set$)', '', fn)\n",
    "\n",
    "y_train = {}\n",
    "for fn in list(data_train.keys()):\n",
    "    base = get_base_filename(fn)\n",
    "    if base in label_map:\n",
    "        y_train[fn] = label_map[base]\n",
    "# keep only matched entries in data_train\n",
    "data_train = {fn: data_train[fn] for fn in y_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series(y_train.values()).value_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we remove the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying Minimal Preprocessing WITHOUT Bandpass Filter (Only Standardization) ---\n",
      "Processed 898 test samples; example shape: (19, 1425)\n",
      "Processed 877 validation samples; example shape: (19, 1425)\n",
      "Processed 10644 train samples; example shape: (19, 1425)\n"
     ]
    }
   ],
   "source": [
    "# Set sampling frequency and disable bandpass by using lowcut=0 and highcut=fs\n",
    "fs = 95\n",
    "\n",
    "print(\"\\n--- Applying Minimal Preprocessing WITHOUT Bandpass Filter (Only Standardization) ---\")\n",
    "\n",
    "# Process TEST set\n",
    "X_test_processed = []\n",
    "for fname, eeg in data_test.items():\n",
    "    processed = preprocess_eegnet_minimal(eeg, fs)\n",
    "    X_test_processed.append(processed)\n",
    "print(f\"Processed {len(X_test_processed)} test samples; example shape: {X_test_processed[0].shape}\")\n",
    "\n",
    "# Process VALIDATION set\n",
    "X_val_processed = []\n",
    "for fname, eeg in data_val.items():\n",
    "    processed = preprocess_eegnet_minimal(eeg, fs)\n",
    "    X_val_processed.append(processed)\n",
    "print(f\"Processed {len(X_val_processed)} validation samples; example shape: {X_val_processed[0].shape}\")\n",
    "\n",
    "# Process TRAIN set\n",
    "X_train_processed = []\n",
    "for fname, eeg in data_train.items():\n",
    "    processed = preprocess_eegnet_minimal(eeg, fs)\n",
    "    X_train_processed.append(processed)\n",
    "print(f\"Processed {len(X_train_processed)} train samples; example shape: {X_train_processed[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We turn datasets into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Converting processed data + labels into tensors & dataloaders ---\n",
      "X_train: torch.Size([10644, 19, 1425]), y_train: torch.Size([10644])\n",
      "X_val  : torch.Size([877, 19, 1425]), y_val  : torch.Size([877])\n",
      "X_test : torch.Size([898, 19, 1425]), y_test : torch.Size([898])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Converting processed data + labels into tensors & dataloaders ---\")\n",
    "\n",
    "# Helper ─ collect labels in the SAME iteration order as the list was built\n",
    "def build_xy_tensors(X_processed_list, y_dict):\n",
    "    \"\"\"\n",
    "    Align X and y by dict iteration order, encode y with LabelEncoder,\n",
    "    and return (X_tensor, y_tensor).\n",
    "    \"\"\"\n",
    "    if not X_processed_list:\n",
    "        raise ValueError(\"The processed X list is empty!\")\n",
    "\n",
    "    # Preserve insertion order of the dict (Python 3.7+ guarantees this)\n",
    "    filenames_order = list(y_dict.keys())\n",
    "\n",
    "    # Sanity check\n",
    "    if len(filenames_order) != len(X_processed_list):\n",
    "        raise RuntimeError(\n",
    "            f\"Mismatch: len(X)={len(X_processed_list)} vs len(y)={len(filenames_order)}. \"\n",
    "            \"Check data alignment.\"\n",
    "        )\n",
    "\n",
    "    # Build y list according to the same order we used when filling X_processed\n",
    "    y_list = [y_dict[fname] for fname in filenames_order]\n",
    "\n",
    "    # --- Label encoding ---\n",
    "    # For consistency across splits, fit once on the union of all labels\n",
    "    global _global_le  # use a single LabelEncoder instance\n",
    "    if '_global_le' not in globals():\n",
    "        _global_le = LabelEncoder()\n",
    "        _global_le.fit(\n",
    "            list(y_train.values()) +\n",
    "            list(y_val.values())   +\n",
    "            list(y_test.values())\n",
    "        )\n",
    "\n",
    "    y_encoded = _global_le.transform(y_list)\n",
    "\n",
    "    # --- Convert to tensors ---\n",
    "    X_np = np.array(X_processed_list)          # shape: (N, C, T)\n",
    "    y_np = np.array(y_encoded, dtype=np.int64) # shape: (N,)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X_np).float()\n",
    "    y_tensor = torch.from_numpy(y_np)          # long by default if dtype not set\n",
    "\n",
    "    return X_tensor, y_tensor\n",
    "\n",
    "# Build tensors for each split\n",
    "X_train_tensor, y_train_tensor = build_xy_tensors(X_train_processed, y_train)\n",
    "\n",
    "# Validation split \n",
    "if X_val_processed:\n",
    "    X_val_tensor, y_val_tensor = build_xy_tensors(X_val_processed, y_val)\n",
    "else:\n",
    "    X_val_tensor = torch.empty((0, *X_train_tensor.shape[1:]), dtype=torch.float32)\n",
    "    y_val_tensor = torch.empty((0,), dtype=torch.long)\n",
    "\n",
    "# Test split\n",
    "if X_test_processed:\n",
    "    X_test_tensor, y_test_tensor = build_xy_tensors(X_test_processed, y_test)\n",
    "else:\n",
    "    X_test_tensor = torch.empty((0, *X_train_tensor.shape[1:]), dtype=torch.float32)\n",
    "    y_test_tensor = torch.empty((0,), dtype=torch.long)\n",
    "\n",
    "# Log shapes\n",
    "print(f\"X_train: {X_train_tensor.shape}, y_train: {y_train_tensor.shape}\")\n",
    "print(f\"X_val  : {X_val_tensor.shape}, y_val  : {y_val_tensor.shape}\")\n",
    "print(f\"X_test : {X_test_tensor.shape}, y_test : {y_test_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes =3   # Number of classes=\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100    # Number of epochs (example, usually needs more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(\n",
    "    X_train_tensor,\n",
    "    y_train_tensor,\n",
    "    X_val_tensor,\n",
    "    y_val_tensor,\n",
    "    X_test_tensor,\n",
    "    y_test_tensor,\n",
    "    *,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=16,\n",
    "    optimizer=\"Adam\",\n",
    "    class_weight=default_class_weight,\n",
    "    dropout_rate=0.5,\n",
    "    num_epochs=100,\n",
    "    weight_decay=1e-4,\n",
    "    F1=8,\n",
    "    D=2,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Full training pipeline for EEGNet model with hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "        X_train_tensor: Training data features\n",
    "        y_train_tensor: Training data labels\n",
    "        X_val_tensor: Validation data features\n",
    "        y_val_tensor: Validation data labels\n",
    "        X_test_tensor: Test data features\n",
    "        y_test_tensor: Test data labels\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        batch_size: Batch size for training\n",
    "        optimizer: Optimizer type (\"Adam\", \"AdamW\", or \"SGD\")\n",
    "        class_weight: Class weights for loss function\n",
    "        dropout_rate: Dropout rate for model\n",
    "        num_epochs: Number of training epochs\n",
    "        weight_decay: L2 regularization strength\n",
    "        F1: Number of temporal filters in EEGNet\n",
    "        D: Depth multiplier in EEGNet\n",
    "        device: Device to run training on\n",
    "        verbose: Whether to print verbose output\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained EEGNet model\n",
    "        loaders: Dictionary of data loaders\n",
    "    \"\"\"\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(X_train_tensor, y_train_tensor),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader, test_loader = None, None\n",
    "    if X_val_tensor is not None and X_val_tensor.shape[0] > 0:\n",
    "        val_loader = DataLoader(\n",
    "            TensorDataset(X_val_tensor, y_val_tensor),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "    if X_test_tensor is not None and X_test_tensor.shape[0] > 0:\n",
    "        test_loader = DataLoader(\n",
    "            TensorDataset(X_test_tensor, y_test_tensor),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "    # Get dimensions and number of classes\n",
    "    n_channels, n_timesteps = X_train_tensor.shape[1], X_train_tensor.shape[2]\n",
    "    num_classes = len(_global_le.classes_)\n",
    "    \n",
    "    # Calculate F2 based on F1 and D\n",
    "    F2 = F1 * D\n",
    "    \n",
    "    # Initialize EEGNet model\n",
    "    model = EEGNet(\n",
    "        n_channels=n_channels,\n",
    "        n_timesteps=n_timesteps,\n",
    "        num_classes=num_classes,\n",
    "        dropout_rate=dropout_rate,\n",
    "        F1=F1,\n",
    "        D=D,\n",
    "        F2=F2\n",
    "    ).to(device)\n",
    "\n",
    "    # Set up loss function with class weights if provided\n",
    "    if class_weight is not None:\n",
    "        if isinstance(class_weight, dict):\n",
    "            cw_tensor = torch.tensor(\n",
    "                [class_weight.get(i, 1.0) for i in range(num_classes)],\n",
    "                dtype=torch.float32,\n",
    "                device=device\n",
    "            )\n",
    "        else:\n",
    "            cw_tensor = class_weight.to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=cw_tensor)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Set up optimizer\n",
    "    opt_name = optimizer.lower()\n",
    "    if opt_name == \"adam\":\n",
    "        optim_obj = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    elif opt_name == \"adamw\":\n",
    "        optim_obj = optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    elif opt_name == \"sgd\":\n",
    "        optim_obj = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            momentum=0.9,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer {optimizer}\")\n",
    "\n",
    "    # Train the model\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        criterion,\n",
    "        optim_obj,\n",
    "        num_epochs,\n",
    "        device\n",
    "    )\n",
    "    \n",
    "    return model, {\"train\": train_loader, \"val\": val_loader, \"test\": test_loader}\n",
    "\n",
    "\n",
    "# Hyperparameter tuning pipeline\n",
    "def run_hyperparameter_tuning(\n",
    "    X_train_tensor, \n",
    "    y_train_tensor,\n",
    "    X_val_tensor, \n",
    "    y_val_tensor,\n",
    "    X_test_tensor, \n",
    "    y_test_tensor,\n",
    "    n_trials=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Run hyperparameter tuning for EEGNet model.\n",
    "    \n",
    "    Args:\n",
    "        X_train_tensor: Training data features\n",
    "        y_train_tensor: Training data labels\n",
    "        X_val_tensor: Validation data features\n",
    "        y_val_tensor: Validation data labels\n",
    "        X_test_tensor: Test data features\n",
    "        y_test_tensor: Test data labels\n",
    "        n_trials: Number of hyperparameter combinations to try\n",
    "        \n",
    "    Returns:\n",
    "        best_model: Best trained model\n",
    "        best_config: Best hyperparameter configuration\n",
    "        best_acc: Best validation accuracy\n",
    "    \"\"\"\n",
    "    # Initialize best trackers\n",
    "    best_acc = 0.0\n",
    "    best_config = None\n",
    "    best_model = None\n",
    "    best_model_path = './best_eegnet_model.pt'\n",
    "\n",
    "    # Define search space for hyperparameters\n",
    "    tune_space = {\n",
    "        \"learning_rate\": np.logspace(-4, -2, num=100),  # continuous log space\n",
    "        \"batch_size\": [16, 24, 32, 40, 48, 56, 64],\n",
    "        \"optimizer\": [\"Adam\", \"AdamW\", \"SGD\"],\n",
    "        \"dropout_rate\": np.linspace(0.3, 0.7, num=5),  # [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        \"num_epochs\": [100],\n",
    "        \"weight_decay\": np.logspace(-3, -1, num=50),\n",
    "        \"F1\": [5, 10, 19, 38, 47, 95],  # Number of temporal filters\n",
    "        \"D\": [2, 3, 4, 5, 6, 7],        # Depth multiplier\n",
    "    }\n",
    "\n",
    "    # Sample random combinations\n",
    "    drawer = list(ParameterSampler(tune_space, n_iter=n_trials, random_state=42))\n",
    "\n",
    "    # Device for training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Loop through each sampled config\n",
    "    for idx, config in enumerate(drawer, 1):\n",
    "        print(f\"\\n=== Configuration {idx}/{n_trials} ===\")\n",
    "        print(config)\n",
    "\n",
    "        # Extract hyperparameters\n",
    "        lr = config[\"learning_rate\"]\n",
    "        bs = config[\"batch_size\"]\n",
    "        opt_name = config[\"optimizer\"]\n",
    "        do_rate = config[\"dropout_rate\"]\n",
    "        epochs = config[\"num_epochs\"]\n",
    "        wd = config[\"weight_decay\"]\n",
    "        f1 = config[\"F1\"]\n",
    "        d = config[\"D\"]\n",
    "\n",
    "        # Train using the pipeline\n",
    "        start_time = time.time()\n",
    "        model, loaders = train_pipeline(\n",
    "            X_train_tensor, y_train_tensor,\n",
    "            X_val_tensor, y_val_tensor,\n",
    "            X_test_tensor, y_test_tensor,\n",
    "            learning_rate=lr,\n",
    "            batch_size=bs,\n",
    "            optimizer=opt_name,\n",
    "            dropout_rate=do_rate,\n",
    "            num_epochs=epochs,\n",
    "            weight_decay=wd,\n",
    "            F1=f1,\n",
    "            D=d,\n",
    "            device=device,\n",
    "            verbose=False\n",
    "        )\n",
    "        train_time = time.time() - start_time\n",
    "        print(f\"Training time: {train_time:.2f} seconds\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loader = loaders[\"val\"]\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            correct, total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for Xb, yb in val_loader:\n",
    "                    Xb, yb = Xb.to(device), yb.to(device)\n",
    "                    out = model(Xb)\n",
    "                    pred = torch.argmax(out, dim=1)\n",
    "                    correct += (pred == yb).sum().item()\n",
    "                    total += yb.size(0)\n",
    "            val_acc = 100 * correct / total\n",
    "            print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "            # Save model if it achieves a new best accuracy\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                best_config = config\n",
    "                best_model = model\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"--> New best model saved! (acc={best_acc:.2f}%)\")\n",
    "\n",
    "    # Print summary of best result\n",
    "    print(f\"\\n==> Best Validation Accuracy: {best_acc:.2f}%\")\n",
    "    print(\"Best Hyperparameters:\", best_config)\n",
    "    print(f\"Best model saved to: {best_model_path}\")\n",
    "    \n",
    "    return best_model, best_config, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data] Train=10644, Val=877, Test=898\n",
      "\n",
      "--- Training EEGNet ---\n",
      "Epoch [1/60], Train Loss: 1.0812, Train Acc: 41.13%, Val Loss: 1.1534, Val Acc: 30.79%\n",
      "Epoch [2/60], Train Loss: 1.0228, Train Acc: 46.85%, Val Loss: 1.1806, Val Acc: 35.01%\n",
      "Epoch [3/60], Train Loss: 0.9654, Train Acc: 52.36%, Val Loss: 1.3493, Val Acc: 37.74%\n",
      "Epoch [4/60], Train Loss: 0.9184, Train Acc: 55.37%, Val Loss: 1.3804, Val Acc: 37.06%\n",
      "Epoch [5/60], Train Loss: 0.8762, Train Acc: 58.01%, Val Loss: 1.3636, Val Acc: 34.44%\n",
      "Epoch [6/60], Train Loss: 0.8357, Train Acc: 59.67%, Val Loss: 1.4769, Val Acc: 35.35%\n",
      "Epoch [7/60], Train Loss: 0.8132, Train Acc: 61.10%, Val Loss: 1.4681, Val Acc: 35.35%\n",
      "Epoch [8/60], Train Loss: 0.7755, Train Acc: 63.39%, Val Loss: 1.5583, Val Acc: 35.46%\n",
      "Epoch [9/60], Train Loss: 0.7547, Train Acc: 64.16%, Val Loss: 1.5164, Val Acc: 35.35%\n",
      "Epoch [10/60], Train Loss: 0.7377, Train Acc: 65.16%, Val Loss: 1.6166, Val Acc: 35.12%\n",
      "Epoch [11/60], Train Loss: 0.7207, Train Acc: 65.50%, Val Loss: 1.7637, Val Acc: 33.41%\n",
      "Epoch [12/60], Train Loss: 0.7110, Train Acc: 66.16%, Val Loss: 1.6844, Val Acc: 33.75%\n",
      "Epoch [13/60], Train Loss: 0.7043, Train Acc: 66.92%, Val Loss: 1.6221, Val Acc: 32.95%\n",
      "Epoch [14/60], Train Loss: 0.6919, Train Acc: 67.61%, Val Loss: 1.7307, Val Acc: 34.21%\n",
      "Epoch [15/60], Train Loss: 0.6821, Train Acc: 67.48%, Val Loss: 1.8041, Val Acc: 35.46%\n",
      "Epoch [16/60], Train Loss: 0.6738, Train Acc: 68.07%, Val Loss: 1.7164, Val Acc: 34.21%\n",
      "Epoch [17/60], Train Loss: 0.6595, Train Acc: 68.63%, Val Loss: 1.7811, Val Acc: 34.55%\n",
      "Epoch [18/60], Train Loss: 0.6601, Train Acc: 68.93%, Val Loss: 1.8422, Val Acc: 33.18%\n",
      "Epoch [19/60], Train Loss: 0.6545, Train Acc: 68.92%, Val Loss: 1.8585, Val Acc: 33.75%\n",
      "Epoch [20/60], Train Loss: 0.6575, Train Acc: 68.53%, Val Loss: 1.9408, Val Acc: 34.21%\n",
      "Epoch [21/60], Train Loss: 0.6330, Train Acc: 69.74%, Val Loss: 1.9733, Val Acc: 33.87%\n",
      "Epoch [22/60], Train Loss: 0.6283, Train Acc: 70.06%, Val Loss: 1.8586, Val Acc: 34.09%\n",
      "Epoch [23/60], Train Loss: 0.6197, Train Acc: 70.54%, Val Loss: 1.9404, Val Acc: 33.98%\n",
      "Epoch [24/60], Train Loss: 0.6099, Train Acc: 70.80%, Val Loss: 2.0532, Val Acc: 33.87%\n",
      "Epoch [25/60], Train Loss: 0.6130, Train Acc: 71.03%, Val Loss: 1.9989, Val Acc: 34.44%\n",
      "Epoch [26/60], Train Loss: 0.6026, Train Acc: 71.22%, Val Loss: 2.0605, Val Acc: 33.75%\n",
      "Epoch [27/60], Train Loss: 0.6052, Train Acc: 71.58%, Val Loss: 1.9950, Val Acc: 33.98%\n",
      "Epoch [28/60], Train Loss: 0.6065, Train Acc: 71.33%, Val Loss: 2.0522, Val Acc: 34.55%\n",
      "Epoch [29/60], Train Loss: 0.5885, Train Acc: 71.97%, Val Loss: 2.0252, Val Acc: 35.35%\n",
      "Epoch [30/60], Train Loss: 0.5933, Train Acc: 72.04%, Val Loss: 2.0644, Val Acc: 34.66%\n",
      "Epoch [31/60], Train Loss: 0.5868, Train Acc: 72.52%, Val Loss: 2.0371, Val Acc: 35.35%\n",
      "Epoch [32/60], Train Loss: 0.5840, Train Acc: 72.59%, Val Loss: 2.1049, Val Acc: 34.55%\n",
      "Epoch [33/60], Train Loss: 0.5728, Train Acc: 73.32%, Val Loss: 2.1007, Val Acc: 35.92%\n",
      "Epoch [34/60], Train Loss: 0.5661, Train Acc: 73.00%, Val Loss: 2.1969, Val Acc: 33.41%\n",
      "Epoch [35/60], Train Loss: 0.5658, Train Acc: 73.00%, Val Loss: 2.0587, Val Acc: 34.89%\n",
      "Epoch [36/60], Train Loss: 0.5642, Train Acc: 73.31%, Val Loss: 2.1851, Val Acc: 35.46%\n",
      "Epoch [37/60], Train Loss: 0.5621, Train Acc: 73.68%, Val Loss: 2.1969, Val Acc: 33.75%\n",
      "Epoch [38/60], Train Loss: 0.5577, Train Acc: 73.45%, Val Loss: 2.2339, Val Acc: 33.87%\n",
      "Epoch [39/60], Train Loss: 0.5519, Train Acc: 73.67%, Val Loss: 2.1797, Val Acc: 35.69%\n",
      "Epoch [40/60], Train Loss: 0.5527, Train Acc: 73.99%, Val Loss: 2.2023, Val Acc: 34.32%\n",
      "Epoch [41/60], Train Loss: 0.5548, Train Acc: 73.61%, Val Loss: 2.2832, Val Acc: 33.75%\n",
      "Epoch [42/60], Train Loss: 0.5443, Train Acc: 73.94%, Val Loss: 2.3302, Val Acc: 33.41%\n",
      "Epoch [43/60], Train Loss: 0.5565, Train Acc: 73.96%, Val Loss: 2.2054, Val Acc: 33.52%\n",
      "Epoch [44/60], Train Loss: 0.5501, Train Acc: 74.29%, Val Loss: 2.2088, Val Acc: 33.75%\n",
      "Epoch [45/60], Train Loss: 0.5454, Train Acc: 74.19%, Val Loss: 2.2894, Val Acc: 34.09%\n",
      "Epoch [46/60], Train Loss: 0.5476, Train Acc: 74.28%, Val Loss: 2.2791, Val Acc: 33.18%\n",
      "Epoch [47/60], Train Loss: 0.5459, Train Acc: 74.06%, Val Loss: 2.3368, Val Acc: 33.52%\n",
      "Epoch [48/60], Train Loss: 0.5465, Train Acc: 74.46%, Val Loss: 2.2752, Val Acc: 34.55%\n",
      "Epoch [49/60], Train Loss: 0.5412, Train Acc: 74.43%, Val Loss: 2.2253, Val Acc: 34.21%\n",
      "Epoch [50/60], Train Loss: 0.5427, Train Acc: 74.32%, Val Loss: 2.2270, Val Acc: 34.21%\n",
      "Epoch [51/60], Train Loss: 0.5438, Train Acc: 74.47%, Val Loss: 2.4263, Val Acc: 33.75%\n",
      "Epoch [52/60], Train Loss: 0.5455, Train Acc: 74.21%, Val Loss: 2.2152, Val Acc: 35.35%\n",
      "Epoch [53/60], Train Loss: 0.5378, Train Acc: 74.91%, Val Loss: 2.2498, Val Acc: 33.41%\n",
      "Epoch [54/60], Train Loss: 0.5377, Train Acc: 74.57%, Val Loss: 2.3056, Val Acc: 33.30%\n",
      "Epoch [55/60], Train Loss: 0.5342, Train Acc: 74.90%, Val Loss: 2.3575, Val Acc: 33.07%\n",
      "Epoch [56/60], Train Loss: 0.5315, Train Acc: 74.77%, Val Loss: 2.3432, Val Acc: 32.50%\n",
      "Epoch [57/60], Train Loss: 0.5334, Train Acc: 75.01%, Val Loss: 2.2703, Val Acc: 32.61%\n",
      "Epoch [58/60], Train Loss: 0.5364, Train Acc: 75.00%, Val Loss: 2.3127, Val Acc: 34.89%\n",
      "Epoch [59/60], Train Loss: 0.5286, Train Acc: 75.12%, Val Loss: 2.3924, Val Acc: 34.78%\n",
      "Epoch [60/60], Train Loss: 0.5289, Train Acc: 75.24%, Val Loss: 2.4189, Val Acc: 33.98%\n",
      "Finished Training EEGNet. Total time: 143.29 seconds\n"
     ]
    }
   ],
   "source": [
    "trained_model, loaders = train_eegnet_pipeline(\n",
    "    X_train_tensor, y_train_tensor,\n",
    "    X_val_tensor,   y_val_tensor,\n",
    "    X_test_tensor,  y_test_tensor,\n",
    "    learning_rate = 3e-4,\n",
    "    batch_size    = 32,\n",
    "    optimizer     = \"AdamW\",\n",
    "    class_weight  = {0:1.0, 1:1.5, 2:2.0},  # 按需设置\n",
    "    dropout_rate  = 0.4,\n",
    "    num_epochs    = 60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "\n",
    "def evaluate_eegnet(\n",
    "    model,\n",
    "    data_loader,\n",
    "    device,\n",
    "    class_names=None,\n",
    "    verbose=True,\n",
    "    plot_confusion=True,\n",
    "    plot_roc=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate a trained EEGNet model on a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : nn.Module\n",
    "        The trained EEGNet model to evaluate\n",
    "    data_loader : DataLoader\n",
    "        DataLoader for the evaluation dataset\n",
    "    device : torch.device\n",
    "        Device to run evaluation on\n",
    "    class_names : list, optional\n",
    "        Names of the classes for better reporting\n",
    "    verbose : bool, default=True\n",
    "        Whether to print evaluation results\n",
    "    plot_confusion : bool, default=True\n",
    "        Whether to plot confusion matrix\n",
    "    plot_roc : bool, default=True\n",
    "        Whether to plot ROC curves\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results : dict\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    if class_names is None and hasattr(data_loader.dataset, 'classes'):\n",
    "        class_names = data_loader.dataset.classes\n",
    "    \n",
    "    # Ensure model is in evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize lists to store predictions and ground truth\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "    \n",
    "    # Disable gradient calculations\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Get probabilities and predictions\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store results\n",
    "            y_true.extend(targets.cpu().numpy())\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "            y_probs.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays for easier handling\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "    \n",
    "    # Get number of classes\n",
    "    num_classes = len(np.unique(y_true)) if class_names is None else len(class_names)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Handle cases where some classes might not be present in the test set\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create classification report\n",
    "    if class_names is not None:\n",
    "        report = classification_report(\n",
    "            y_true, y_pred, \n",
    "            target_names=class_names, \n",
    "            output_dict=True, \n",
    "            zero_division=0\n",
    "        )\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "    else:\n",
    "        report = classification_report(\n",
    "            y_true, y_pred,\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Prepare ROC curve data\n",
    "    if num_classes == 2:\n",
    "        # Binary classification\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_probs[:, 1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        roc_data = [(fpr, tpr, roc_auc, \"ROC curve\")]\n",
    "    else:\n",
    "        # Multi-class classification\n",
    "        roc_data = []\n",
    "        # One-vs-rest ROC curves for each class\n",
    "        for i in range(num_classes):\n",
    "            class_label = class_names[i] if class_names is not None else f\"Class {i}\"\n",
    "            fpr, tpr, _ = roc_curve((y_true == i).astype(int), y_probs[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            roc_data.append((fpr, tpr, roc_auc, f\"ROC curve for {class_label}\"))\n",
    "    \n",
    "    # Print results if verbose\n",
    "    if verbose:\n",
    "        print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "        print(f\"Precision: {precision*100:.2f}%\")\n",
    "        print(f\"Recall: {recall*100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1*100:.2f}%\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report_df[[\"precision\", \"recall\", \"f1-score\", \"support\"]])\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    if plot_confusion:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        tick_marks = np.arange(num_classes)\n",
    "        plt.xticks(tick_marks, class_names if class_names else tick_marks)\n",
    "        plt.yticks(tick_marks, class_names if class_names else tick_marks)\n",
    "        \n",
    "        # Add text annotations to the confusion matrix\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                        horizontalalignment=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.ylabel('True label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot ROC curves\n",
    "    if plot_roc:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for fpr, tpr, roc_auc, label in roc_data:\n",
    "            plt.plot(fpr, tpr, lw=2, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    # Prepare results dictionary\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report_df,\n",
    "        'roc_data': roc_data,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'y_probs': y_probs\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "My Custom Env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
