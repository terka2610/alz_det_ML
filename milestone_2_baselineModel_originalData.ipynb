{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96feecd3-cecb-4c41-ace7-39482b017ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import mne\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore RuntimeWarning\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Enable CUDA\n",
    "mne.utils.set_config('MNE_USE_CUDA', 'true')\n",
    "mne.cuda.init_cuda(verbose=False)  # Set to True for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f129ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg_data(file_path):\n",
    "    \"\"\"Load EEG data from EEGLAB file\"\"\"\n",
    "    try:\n",
    "        raw = mne.io.read_raw_eeglab(file_path)\n",
    "        return raw.get_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "class EEGRFDataset:\n",
    "    \"\"\"\n",
    "    Dataset handler for EEG data to be used with Random Forest models.\n",
    "    Loads and preprocesses EEG data from files.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, data_info=None, scaler=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset handler.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): Directory containing the EEG data files\n",
    "            data_info (list): List of dictionaries containing file information\n",
    "                             (if None, will try to load from labels.json)\n",
    "            scaler (StandardScaler): Pre-fitted scaler for feature normalization\n",
    "                                    (if None, a new one will be created and fitted)\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        # Load data info if not provided\n",
    "        if data_info is None:\n",
    "            with open(os.path.join(data_dir, 'labels.json'), 'r') as f:\n",
    "                self.data_info = json.load(f)\n",
    "        else:\n",
    "            self.data_info = data_info\n",
    "\n",
    "        self.scaler = scaler\n",
    "\n",
    "        # Generate data and labels lists\n",
    "        self.data = [d['file_name'] for d in self.data_info]\n",
    "        self.labels = [0 if d['label'] == 'A' else 1 if d['label'] == 'C' else 2 for d in self.data_info]\n",
    "\n",
    "    def load_data(self, data_type=None):\n",
    "        \"\"\"\n",
    "        Load and preprocess the EEG data.\n",
    "\n",
    "        Args:\n",
    "            data_type (str, optional): Type of data to load (e.g., 'train', 'test_cross', 'test_within')\n",
    "                                      If None, all data will be loaded.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (X, y) where X is the feature matrix and y contains the labels\n",
    "        \"\"\"\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # Filter by data type if specified\n",
    "        if data_type is not None:\n",
    "            filtered_info = [d for d in self.data_info if d['type'] == data_type]\n",
    "        else:\n",
    "            filtered_info = self.data_info\n",
    "\n",
    "        print(f\"Loading {len(filtered_info)} EEG samples for {data_type}...\")\n",
    "\n",
    "        # Load each EEG file\n",
    "        for item in filtered_info:\n",
    "            file_path = os.path.join(self.data_dir, item['file_name'])\n",
    "            label = 0 if item['label'] == 'A' else 1 if item['label'] == 'C' else 2\n",
    "\n",
    "            # Load the EEG data from the file\n",
    "            eeg_data = load_eeg_data(file_path)\n",
    "\n",
    "            if eeg_data is not None:\n",
    "                # Preprocess EEG data for Random Forest\n",
    "                features = self._preprocess_eeg(eeg_data)\n",
    "\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        if len(X) == 0:\n",
    "            raise ValueError(f\"No valid data loaded for {data_type}. Please check file paths and data format.\")\n",
    "\n",
    "        # Create and fit scaler if not provided\n",
    "        if self.scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            X = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            X = self.scaler.transform(X)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def _preprocess_eeg(self, eeg_data):\n",
    "        \"\"\"\n",
    "        Preprocess the EEG data for Random Forest input.\n",
    "\n",
    "        Args:\n",
    "            eeg_data (numpy.ndarray): Raw EEG data\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Preprocessed features\n",
    "        \"\"\"\n",
    "        # Assuming eeg_data shape is (channels, samples) or (samples, channels)\n",
    "        # If data is (samples, channels), transpose it\n",
    "        if eeg_data.shape[0] > eeg_data.shape[1]:\n",
    "            eeg_data = eeg_data.T\n",
    "\n",
    "        num_channels = eeg_data.shape[0]\n",
    "\n",
    "        # Feature extraction\n",
    "        features = []\n",
    "\n",
    "        # Time domain and frequency domain features for Random Forest\n",
    "        for channel in range(num_channels):\n",
    "            channel_data = eeg_data[channel, :]\n",
    "\n",
    "            # Time domain features\n",
    "            features.extend([\n",
    "                np.mean(channel_data),\n",
    "                np.std(channel_data),\n",
    "                np.max(channel_data),\n",
    "                np.min(channel_data),\n",
    "                np.percentile(channel_data, 75) - np.percentile(channel_data, 25)\n",
    "            ])\n",
    "\n",
    "            # Frequency domain features\n",
    "            fft_data = np.abs(np.fft.rfft(channel_data))\n",
    "            # Normalized frequency band powers\n",
    "            total_power = np.sum(fft_data)\n",
    "            features.extend([\n",
    "                np.sum(fft_data[:5]) / total_power,  # Delta\n",
    "                np.sum(fft_data[5:12]) / total_power,  # Theta\n",
    "                np.sum(fft_data[12:30]) / total_power,  # Alpha\n",
    "                np.sum(fft_data[30:80]) / total_power,  # Beta\n",
    "                np.sum(fft_data[80:]) / total_power  # Gamma\n",
    "            ])\n",
    "\n",
    "        return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGRF:\n",
    "    \"\"\"\n",
    "    Random Forest model for EEG classification with hyperparameter optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=100, max_depth=None, class_weight=None):\n",
    "        \"\"\"\n",
    "        Initialize the Random Forest model.\n",
    "\n",
    "        Args:\n",
    "            n_estimators (int): Number of trees in the forest\n",
    "            max_depth (int or None): The maximum depth of the trees\n",
    "            class_weight (dict or 'balanced'): Weights associated with classes in the form {class_label: weight}\n",
    "        \"\"\"\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            class_weight=class_weight,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the Random Forest model.\n",
    "\n",
    "        Args:\n",
    "            X_train (numpy.ndarray): Training features\n",
    "            y_train (numpy.ndarray): Training labels\n",
    "\n",
    "        Returns:\n",
    "            EEGRF: Self for method chaining\n",
    "        \"\"\"\n",
    "        print(\"Training Random Forest model...\")\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        train_pred = self.model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with the trained model.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Features\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predictions\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data.\n",
    "\n",
    "        Args:\n",
    "            X_test (numpy.ndarray): Test features\n",
    "            y_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47df7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EEGSVM:\n",
    "    \"\"\"\n",
    "    Support Vector Machine model for EEG classification with hyperparameter optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C=1.0, kernel='rbf', class_weight=None):\n",
    "        \"\"\"\n",
    "        Initialize the SVM model.\n",
    "\n",
    "        Args:\n",
    "            C (float): Regularization parameter\n",
    "            kernel (str): Kernel type to be used in the algorithm\n",
    "            class_weight (dict or 'balanced'): Weights associated with classes\n",
    "        \"\"\"\n",
    "        # Initialize the SVC with given hyperparameters\n",
    "        self.model = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            class_weight=class_weight,\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the SVM model.\n",
    "\n",
    "        Args:\n",
    "            X_train (numpy.ndarray): Training features\n",
    "            y_train (numpy.ndarray): Training labels\n",
    "\n",
    "        Returns:\n",
    "            EEGSVM: Self for method chaining\n",
    "        \"\"\"\n",
    "        print(\"Training SVM model...\")\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        train_pred = self.model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with the trained model.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Features\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predictions\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data.\n",
    "\n",
    "        Args:\n",
    "            X_test (numpy.ndarray): Test features\n",
    "            y_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2bde69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGGradientBoost:\n",
    "    \"\"\"\n",
    "    Gradient Boosting model for EEG classification with hyperparameter optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, subsample=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the Gradient Boosting model.\n",
    "\n",
    "        Args:\n",
    "            n_estimators (int): Number of boosting stages\n",
    "            learning_rate (float): Learning rate shrinks the contribution of each tree\n",
    "            max_depth (int): Maximum depth of the individual regression estimators\n",
    "            subsample (float): The fraction of samples to be used for fitting the individual base learners\n",
    "        \"\"\"\n",
    "        # Initialize the GradientBoostingClassifier with given hyperparameters\n",
    "        self.model = GradientBoostingClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            max_depth=max_depth,\n",
    "            subsample=subsample,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the Gradient Boosting model.\n",
    "\n",
    "        Args:\n",
    "            X_train (numpy.ndarray): Training features\n",
    "            y_train (numpy.ndarray): Training labels\n",
    "\n",
    "        Returns:\n",
    "            EEGGradientBoost: Self for method chaining\n",
    "        \"\"\"\n",
    "        print(\"Training Gradient Boosting model...\")\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        train_pred = self.model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with the trained model.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Features\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predictions\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data.\n",
    "\n",
    "        Args:\n",
    "            X_test (numpy.ndarray): Test features\n",
    "            y_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7fd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_results(results, data_type):\n",
    "    \"\"\"Print detailed evaluation results in a formatted way\"\"\"\n",
    "    print(f\"\\n===== {data_type} Results =====\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {results['f1']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Calculate per-class metrics from confusion matrix\n",
    "    cm = results['confusion_matrix']\n",
    "    classes = ['A', 'C', 'F']\n",
    "    \n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        # True positives: diagonal elements\n",
    "        tp = cm[i, i]\n",
    "        # False positives: sum of column i minus diagonal element\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        # False negatives: sum of row i minus diagonal element\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        # True negatives: sum of all elements minus tp, fp, fn\n",
    "        tn = np.sum(cm) - tp - fp - fn\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"Class {cls}:\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42a8bdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EEGRFDataset at 0x2b18322a7d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"model-data\"\n",
    "\n",
    "# Create dataset handler\n",
    "dataset = EEGRFDataset(data_dir)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e68d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 3219 EEG samples for train...\n",
      "Loaded training data: (3219, 190) features, 3219 labels\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "X_train, y_train = dataset.load_data(data_type='train')\n",
    "print(f\"Loaded training data: {X_train.shape} features, {len(y_train)} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e6e56ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Training accuracy: 1.0000\n",
      "\n",
      "Evaluating on test_cross data (different subjects)...\n",
      "Loading 873 EEG samples for test_cross...\n",
      "Loaded test_cross data: (873, 190) features, 873 labels\n",
      "\n",
      "===== Test Cross-Subject Results =====\n",
      "Accuracy: 0.4845\n",
      "Precision: 0.5833\n",
      "Recall: 0.4845\n",
      "F1 Score: 0.4556\n",
      "\n",
      "Confusion Matrix:\n",
      "[[206 110   3]\n",
      " [123 180   4]\n",
      " [179  31  37]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.4055\n",
      "  Recall: 0.6458\n",
      "  F1 Score: 0.4982\n",
      "Class C:\n",
      "  Precision: 0.5607\n",
      "  Recall: 0.5863\n",
      "  F1 Score: 0.5732\n",
      "Class F:\n",
      "  Precision: 0.8409\n",
      "  Recall: 0.1498\n",
      "  F1 Score: 0.2543\n",
      "\n",
      "Evaluating on test_within data (same subjects)...\n",
      "Loading 344 EEG samples for test_within...\n",
      "Loaded test_within data: (344, 190) features, 344 labels\n",
      "\n",
      "===== Test Within-Subject Results =====\n",
      "Accuracy: 0.7471\n",
      "Precision: 0.7856\n",
      "Recall: 0.7471\n",
      "F1 Score: 0.7325\n",
      "\n",
      "Confusion Matrix:\n",
      "[[131  15   0]\n",
      " [ 26  99   1]\n",
      " [ 37   8  27]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.6753\n",
      "  Recall: 0.8973\n",
      "  F1 Score: 0.7706\n",
      "Class C:\n",
      "  Precision: 0.8115\n",
      "  Recall: 0.7857\n",
      "  F1 Score: 0.7984\n",
      "Class F:\n",
      "  Precision: 0.9643\n",
      "  Recall: 0.3750\n",
      "  F1 Score: 0.5400\n",
      "\n",
      "Evaluating on combined test data...\n",
      "\n",
      "===== Combined Test Results =====\n",
      "Accuracy: 0.5588\n",
      "Precision: 0.6405\n",
      "Recall: 0.5588\n",
      "F1 Score: 0.5331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[337 125   3]\n",
      " [149 279   5]\n",
      " [216  39  64]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.4801\n",
      "  Recall: 0.7247\n",
      "  F1 Score: 0.5775\n",
      "Class C:\n",
      "  Precision: 0.6298\n",
      "  Recall: 0.6443\n",
      "  F1 Score: 0.6370\n",
      "Class F:\n",
      "  Precision: 0.8889\n",
      "  Recall: 0.2006\n",
      "  F1 Score: 0.3274\n",
      "\n",
      "Random Forest evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "rf_model = EEGRF(n_estimators=100, max_depth=None, class_weight='balanced')\n",
    "rf_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate on test_cross data\n",
    "print(\"\\nEvaluating on test_cross data (different subjects)...\")\n",
    "X_test_cross, y_test_cross = dataset.load_data(data_type='test_cross')\n",
    "print(f\"Loaded test_cross data: {X_test_cross.shape} features, {len(y_test_cross)} labels\")\n",
    "\n",
    "if len(y_test_cross) > 0:\n",
    "    results_cross = rf_model.evaluate(X_test_cross, y_test_cross)\n",
    "    print_evaluation_results(results_cross, \"Test Cross-Subject\")\n",
    "else:\n",
    "    print(\"No test_cross data available.\")\n",
    "\n",
    "# Evaluate on test_within data\n",
    "print(\"\\nEvaluating on test_within data (same subjects)...\")\n",
    "X_test_within, y_test_within = dataset.load_data(data_type='test_within')\n",
    "print(f\"Loaded test_within data: {X_test_within.shape} features, {len(y_test_within)} labels\")\n",
    "\n",
    "if len(y_test_within) > 0:\n",
    "    results_within = rf_model.evaluate(X_test_within, y_test_within)\n",
    "    print_evaluation_results(results_within, \"Test Within-Subject\")\n",
    "else:\n",
    "    print(\"No test_within data available.\")\n",
    "\n",
    "# Calculate and print overall metrics (combined test sets)\n",
    "if len(y_test_cross) > 0 and len(y_test_within) > 0:\n",
    "    print(\"\\nEvaluating on combined test data...\")\n",
    "    X_test_combined = np.vstack([X_test_cross, X_test_within])\n",
    "    y_test_combined = np.concatenate([y_test_cross, y_test_within])\n",
    "    results_combined = rf_model.evaluate(X_test_combined, y_test_combined)\n",
    "    print_evaluation_results(results_combined, \"Combined Test\")\n",
    "\n",
    "print(\"\\nRandom Forest evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6ae448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "Training accuracy: 0.8136\n",
      "\n",
      "Evaluating SVM on test_cross data (different subjects)...\n",
      "Loading 873 EEG samples for test_cross...\n",
      "Loaded test_cross data: (873, 190) features, 873 labels\n",
      "\n",
      "===== SVM Test Cross-Subject Results =====\n",
      "Accuracy: 0.5074\n",
      "Precision: 0.5140\n",
      "Recall: 0.5074\n",
      "F1 Score: 0.5054\n",
      "\n",
      "Confusion Matrix:\n",
      "[[175 108  36]\n",
      " [ 89 173  45]\n",
      " [122  30  95]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.4534\n",
      "  Recall: 0.5486\n",
      "  F1 Score: 0.4965\n",
      "Class C:\n",
      "  Precision: 0.5563\n",
      "  Recall: 0.5635\n",
      "  F1 Score: 0.5599\n",
      "Class F:\n",
      "  Precision: 0.5398\n",
      "  Recall: 0.3846\n",
      "  F1 Score: 0.4492\n",
      "\n",
      "Evaluating SVM on test_within data (same subjects)...\n",
      "Loading 344 EEG samples for test_within...\n",
      "Loaded test_within data: (344, 190) features, 344 labels\n",
      "\n",
      "===== SVM Test Within-Subject Results =====\n",
      "Accuracy: 0.7267\n",
      "Precision: 0.7398\n",
      "Recall: 0.7267\n",
      "F1 Score: 0.7310\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103  13  30]\n",
      " [ 17  98  11]\n",
      " [ 17   6  49]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.7518\n",
      "  Recall: 0.7055\n",
      "  F1 Score: 0.7279\n",
      "Class C:\n",
      "  Precision: 0.8376\n",
      "  Recall: 0.7778\n",
      "  F1 Score: 0.8066\n",
      "Class F:\n",
      "  Precision: 0.5444\n",
      "  Recall: 0.6806\n",
      "  F1 Score: 0.6049\n",
      "\n",
      "Evaluating SVM on combined test data...\n",
      "\n",
      "===== SVM Combined Test Results =====\n",
      "Accuracy: 0.5694\n",
      "Precision: 0.5703\n",
      "Recall: 0.5694\n",
      "F1 Score: 0.5680\n",
      "\n",
      "Confusion Matrix:\n",
      "[[278 121  66]\n",
      " [106 271  56]\n",
      " [139  36 144]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.5315\n",
      "  Recall: 0.5978\n",
      "  F1 Score: 0.5628\n",
      "Class C:\n",
      "  Precision: 0.6332\n",
      "  Recall: 0.6259\n",
      "  F1 Score: 0.6295\n",
      "Class F:\n",
      "  Precision: 0.5414\n",
      "  Recall: 0.4514\n",
      "  F1 Score: 0.4923\n",
      "\n",
      "SVM evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm_model = EEGSVM(C=1.0, kernel='rbf', class_weight='balanced')\n",
    "svm_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate on test_cross data\n",
    "print(\"\\nEvaluating SVM on test_cross data (different subjects)...\")\n",
    "X_test_cross, y_test_cross = dataset.load_data(data_type='test_cross')\n",
    "print(f\"Loaded test_cross data: {X_test_cross.shape} features, {len(y_test_cross)} labels\")\n",
    "\n",
    "if len(y_test_cross) > 0:\n",
    "    results_cross = svm_model.evaluate(X_test_cross, y_test_cross)\n",
    "    print_evaluation_results(results_cross, \"SVM Test Cross-Subject\")\n",
    "else:\n",
    "    print(\"No test_cross data available for SVM.\")\n",
    "\n",
    "# Evaluate on test_within data\n",
    "print(\"\\nEvaluating SVM on test_within data (same subjects)...\")\n",
    "X_test_within, y_test_within = dataset.load_data(data_type='test_within')\n",
    "print(f\"Loaded test_within data: {X_test_within.shape} features, {len(y_test_within)} labels\")\n",
    "\n",
    "if len(y_test_within) > 0:\n",
    "    results_within = svm_model.evaluate(X_test_within, y_test_within)\n",
    "    print_evaluation_results(results_within, \"SVM Test Within-Subject\")\n",
    "else:\n",
    "    print(\"No test_within data available for SVM.\")\n",
    "\n",
    "# Combined evaluation\n",
    "if len(y_test_cross) > 0 and len(y_test_within) > 0:\n",
    "    print(\"\\nEvaluating SVM on combined test data...\")\n",
    "    X_test_combined = np.vstack([X_test_cross, X_test_within])\n",
    "    y_test_combined = np.concatenate([y_test_cross, y_test_within])\n",
    "    results_combined = svm_model.evaluate(X_test_combined, y_test_combined)\n",
    "    print_evaluation_results(results_combined, \"SVM Combined Test\")\n",
    "\n",
    "print(\"\\nSVM evaluation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39389a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting model...\n",
      "Training accuracy: 0.8975\n",
      "\n",
      "Evaluating Gradient Boosting on test_cross data (different subjects)...\n",
      "Loading 873 EEG samples for test_cross...\n",
      "Loaded test_cross data: (873, 190) features, 873 labels\n",
      "\n",
      "===== GB Test Cross-Subject Results =====\n",
      "Accuracy: 0.4914\n",
      "Precision: 0.5133\n",
      "Recall: 0.4914\n",
      "F1 Score: 0.4733\n",
      "\n",
      "Confusion Matrix:\n",
      "[[183 119  17]\n",
      " [ 93 193  21]\n",
      " [155  39  53]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.4246\n",
      "  Recall: 0.5737\n",
      "  F1 Score: 0.4880\n",
      "Class C:\n",
      "  Precision: 0.5499\n",
      "  Recall: 0.6287\n",
      "  F1 Score: 0.5866\n",
      "Class F:\n",
      "  Precision: 0.5824\n",
      "  Recall: 0.2146\n",
      "  F1 Score: 0.3136\n",
      "\n",
      "Evaluating Gradient Boosting on test_within data (same subjects)...\n",
      "Loading 344 EEG samples for test_within...\n",
      "Loaded test_within data: (344, 190) features, 344 labels\n",
      "\n",
      "===== GB Test Within-Subject Results =====\n",
      "Accuracy: 0.7762\n",
      "Precision: 0.7762\n",
      "Recall: 0.7762\n",
      "F1 Score: 0.7713\n",
      "\n",
      "Confusion Matrix:\n",
      "[[125  10  11]\n",
      " [ 18 104   4]\n",
      " [ 26   8  38]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.7396\n",
      "  Recall: 0.8562\n",
      "  F1 Score: 0.7937\n",
      "Class C:\n",
      "  Precision: 0.8525\n",
      "  Recall: 0.8254\n",
      "  F1 Score: 0.8387\n",
      "Class F:\n",
      "  Precision: 0.7170\n",
      "  Recall: 0.5278\n",
      "  F1 Score: 0.6080\n",
      "\n",
      "Evaluating Gradient Boosting on combined test data...\n",
      "\n",
      "===== GB Combined Test Results =====\n",
      "Accuracy: 0.5719\n",
      "Precision: 0.5852\n",
      "Recall: 0.5719\n",
      "F1 Score: 0.5573\n",
      "\n",
      "Confusion Matrix:\n",
      "[[308 129  28]\n",
      " [111 297  25]\n",
      " [181  47  91]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.5133\n",
      "  Recall: 0.6624\n",
      "  F1 Score: 0.5784\n",
      "Class C:\n",
      "  Precision: 0.6279\n",
      "  Recall: 0.6859\n",
      "  F1 Score: 0.6556\n",
      "Class F:\n",
      "  Precision: 0.6319\n",
      "  Recall: 0.2853\n",
      "  F1 Score: 0.3931\n",
      "\n",
      "Gradient Boosting evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize and train the Gradient Boosting model\n",
    "gb_model = EEGGradientBoost(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    subsample=1.0\n",
    ")\n",
    "gb_model.train(X_train, y_train)\n",
    "\n",
    "# Evaluate on test_cross data\n",
    "print(\"\\nEvaluating Gradient Boosting on test_cross data (different subjects)...\")\n",
    "X_test_cross, y_test_cross = dataset.load_data(data_type='test_cross')\n",
    "print(f\"Loaded test_cross data: {X_test_cross.shape} features, {len(y_test_cross)} labels\")\n",
    "\n",
    "if len(y_test_cross) > 0:\n",
    "    results_cross = gb_model.evaluate(X_test_cross, y_test_cross)\n",
    "    print_evaluation_results(results_cross, \"GB Test Cross-Subject\")\n",
    "else:\n",
    "    print(\"No test_cross data available for Gradient Boosting.\")\n",
    "\n",
    "# Evaluate on test_within data\n",
    "print(\"\\nEvaluating Gradient Boosting on test_within data (same subjects)...\")\n",
    "X_test_within, y_test_within = dataset.load_data(data_type='test_within')\n",
    "print(f\"Loaded test_within data: {X_test_within.shape} features, {len(y_test_within)} labels\")\n",
    "\n",
    "if len(y_test_within) > 0:\n",
    "    results_within = gb_model.evaluate(X_test_within, y_test_within)\n",
    "    print_evaluation_results(results_within, \"GB Test Within-Subject\")\n",
    "else:\n",
    "    print(\"No test_within data available for Gradient Boosting.\")\n",
    "\n",
    "# Combined evaluation\n",
    "if len(y_test_cross) > 0 and len(y_test_within) > 0:\n",
    "    print(\"\\nEvaluating Gradient Boosting on combined test data...\")\n",
    "    X_test_combined = np.vstack([X_test_cross, X_test_within])\n",
    "    y_test_combined = np.concatenate([y_test_cross, y_test_within])\n",
    "    results_combined = gb_model.evaluate(X_test_combined, y_test_combined)\n",
    "    print_evaluation_results(results_combined, \"GB Combined Test\")\n",
    "\n",
    "print(\"\\nGradient Boosting evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
