{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import mne\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time # To measure time\n",
    "\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import detrend, butter, filtfilt\n",
    "import pywt\n",
    "\n",
    "\n",
    "from scipy.signal import resample\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_float, img_as_ubyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load subject labels\n",
    "with open(\"model-data/Labels_epochs.json\", \"r\") as f:\n",
    "    subject_labels = json.load(f)\n",
    "\n",
    "def load_data(directory):\n",
    "    \"\"\"\n",
    "    Loads and returns augmented EEG data (X) and corresponding labels (y) from the specified directory.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".npy\"):\n",
    "            # Load the features (EEG data)\n",
    "            X_data = np.load(os.path.join(directory, file))\n",
    "            # Load corresponding label (subject ID matches file naming convention)\n",
    "            subject_id = file.split(\"_\")[0]\n",
    "            label = subject_labels.get(subject_id, None)\n",
    "            if label is not None:\n",
    "                X.append(X_data)\n",
    "                y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Assume fs (sampling frequency) is known. For example, fs = 250 Hz\n",
    "fs = 250.0  # Replace this with the actual sampling frequency\n",
    "\n",
    "# Define your preprocessing function\n",
    "def preprocess_eeg_data(X, fs, lowcut=1.0, highcut=40.0, order=5):\n",
    "    \"\"\"\n",
    "    Applies preprocessing steps to EEG data:\n",
    "    - Bandpass filtering\n",
    "    - Channel-wise standardization (z-score normalization)\n",
    "    \n",
    "    Args:\n",
    "        X (np.ndarray): Raw EEG data (n_subjects, n_epochs, n_channels, n_timesteps).\n",
    "        fs (float): Original sampling frequency.\n",
    "        lowcut (float): Lower cutoff frequency for bandpass filter (Hz).\n",
    "        highcut (float): Upper cutoff frequency for bandpass filter (Hz).\n",
    "        order (int): Order of the Butterworth filter.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed EEG data (n_subjects, n_epochs, n_channels, n_timesteps).\n",
    "    \"\"\"\n",
    "    n_subjects, n_epochs, n_channels, n_timesteps = X.shape\n",
    "    processed_data = np.zeros_like(X)\n",
    "\n",
    "    # 1. Bandpass Filter Design\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    if low <= 0 or high >= 1:\n",
    "        print(f\"Warning: Filter frequencies ({lowcut}Hz, {highcut}Hz) are invalid for Nyquist freq {nyq}Hz. Skipping filter.\")\n",
    "        b, a = None, None\n",
    "    else:\n",
    "        try:\n",
    "            b, a = butter(order, [low, high], btype='band')\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Could not design Butterworth filter (order={order}, freqs=[{low}, {high}]). Skipping filter. Error: {e}\")\n",
    "            b, a = None, None\n",
    "\n",
    "    # 2. Apply Filter and Standardize Channel by Channel\n",
    "    for i_subj in range(n_subjects):\n",
    "        for i_epoch in range(n_epochs):\n",
    "            for i_ch in range(n_channels):\n",
    "                channel_data = X[i_subj, i_epoch, i_ch, :]\n",
    "\n",
    "                # Apply bandpass filter if designed\n",
    "                if b is not None and a is not None:\n",
    "                    try:\n",
    "                        filtered_data = filtfilt(b, a, channel_data)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Filtering failed for subject {i_subj}, epoch {i_epoch}, channel {i_ch}. Using original data. Error: {e}\")\n",
    "                        filtered_data = channel_data\n",
    "                else:\n",
    "                    filtered_data = channel_data  # Use original if no filter\n",
    "\n",
    "                # Standardize (z-score normalization)\n",
    "                mean = np.mean(filtered_data)\n",
    "                std = np.std(filtered_data)\n",
    "                if std > 1e-9:\n",
    "                    processed_data[i_subj, i_epoch, i_ch, :] = (filtered_data - mean) / std\n",
    "                else:\n",
    "                    processed_data[i_subj, i_epoch, i_ch, :] = filtered_data - mean  # Only center if std is zero\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Rakhmatulin et al., 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify your EEGNet class to fix the device mismatch\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_timesteps, num_classes,\n",
    "                 F1=8, D=2, F2=16, kernel_length=64, dropout_rate=0.5):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.num_classes = num_classes\n",
    "        self.F1 = F1\n",
    "        self.D = D\n",
    "        self.F2 = F2\n",
    "        self.kernel_length = kernel_length\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Block 1: Temporal Convolution + Depthwise Spatial Convolution\n",
    "        self.conv1 = nn.Conv2d(19, self.F1, (1, self.kernel_length), padding=(0, self.kernel_length // 2), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.F1)\n",
    "        \n",
    "        # Depthwise Conv: applied to each feature map spatially (across channels)\n",
    "        self.depthwise_conv = nn.Conv2d(self.F1, self.F1 * self.D, (self.n_channels, 1), groups=self.F1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(self.F1 * self.D)\n",
    "        \n",
    "        # Pooling (downsampling)\n",
    "        self.pool1 = nn.AvgPool2d((1, 4))  # Downsample the time dimension\n",
    "        \n",
    "        # Block 2: Separable Convolution\n",
    "        separable_kernel_length = 16\n",
    "        self.separable_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.F1 * self.D, self.F1 * self.D, (1, separable_kernel_length),\n",
    "                      padding=(0, separable_kernel_length // 2), groups=self.F1 * self.D, bias=False),\n",
    "            nn.Conv2d(self.F1 * self.D, self.F2, (1, 1), bias=False)\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(self.F2)\n",
    "        self.pool2 = nn.AvgPool2d((1, 8))  # Further downsampling\n",
    "        \n",
    "        # Based on your previous output, the flattened size is 41280\n",
    "        flatten_size = 41280  # This value comes from your shape output\n",
    "        self.fc_out = nn.Linear(flatten_size, self.num_classes)\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.depthwise_conv(x)\n",
    "        x = F.elu(self.bn2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Block 2\n",
    "        x = self.separable_conv(x)\n",
    "        x = F.elu(self.bn3(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Print the shape before flattening (for debugging)\n",
    "        print(\"Shape before flattening:\", x.shape)\n",
    "        \n",
    "        # Flatten the tensor dynamically\n",
    "        x = x.view(x.size(0), -1)  # This flattens the tensor\n",
    "        \n",
    "        # Print the shape after flattening (for debugging)\n",
    "        print(\"Shape after flattening:\", x.shape)\n",
    "        \n",
    "        # Fully connected layer output\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the input data shape before passing to the model in the training loop\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)  # Move model to the designated device\n",
    "    total_train_steps = len(train_loader)\n",
    "    if val_loader:\n",
    "        total_val_steps = len(val_loader)\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"\\n--- Training {model.__class__.__name__} ---\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training Phase ---\n",
    "        model.train()  # Set the model to training mode\n",
    "        epoch_train_loss = 0.0\n",
    "        train_correct_predictions = 0\n",
    "        train_total_samples = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Move data to the designated device\n",
    "            inputs = inputs.to(device)  # Shape: (batch_size, 476, 19, 190)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Reshape inputs from (batch_size, 476, 19, 190) to (batch_size, 19, 190, 476)\n",
    "            inputs = inputs.permute(0, 2, 3, 1)  # This changes the shape to (batch_size, 19, 190, 476)\n",
    "            # Now inputs are (batch_size, 19, 190, 476), which matches the expected input for the model\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)  # Model expects input shape (batch_size, 19, 190)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate training statistics\n",
    "            epoch_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total_samples += labels.size(0)\n",
    "            train_correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate average training loss and accuracy for the epoch\n",
    "        avg_epoch_train_loss = epoch_train_loss / total_train_steps\n",
    "        epoch_train_accuracy = 100 * train_correct_predictions / train_total_samples\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        if val_loader is not None:\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            epoch_val_loss = 0.0\n",
    "            val_correct_predictions = 0\n",
    "            val_total_samples = 0\n",
    "\n",
    "            with torch.no_grad():  # Disable gradient calculations during validation\n",
    "                for val_inputs, val_labels in val_loader:\n",
    "                    # Move data to the designated device\n",
    "                    val_inputs = val_inputs.to(device)  # Shape: (batch_size, 476, 19, 190)\n",
    "                    val_labels = val_labels.to(device)\n",
    "\n",
    "                    # Reshape validation inputs from (batch_size, 476, 19, 190) to (batch_size, 19, 190, 476)\n",
    "                    val_inputs = val_inputs.permute(0, 2, 3, 1)  # Shape: (batch_size, 19, 190, 476)\n",
    "\n",
    "                    # Forward pass\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss_batch = criterion(val_outputs, val_labels)\n",
    "\n",
    "                    # Accumulate validation statistics\n",
    "                    epoch_val_loss += val_loss_batch.item()\n",
    "                    _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                    val_total_samples += val_labels.size(0)\n",
    "                    val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "            # Calculate average validation loss and accuracy for the epoch\n",
    "            avg_epoch_val_loss = epoch_val_loss / total_val_steps\n",
    "            epoch_val_accuracy = 100 * val_correct_predictions / val_total_samples\n",
    "\n",
    "            # Print combined epoch results\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {avg_epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.2f}%, '\n",
    "                  f'Val Loss: {avg_epoch_val_loss:.4f}, Val Acc: {epoch_val_accuracy:.2f}%')\n",
    "        else:\n",
    "            # Print only training results if no validation loader is provided\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {avg_epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.2f}%')\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished Training {model.__class__.__name__}. Total time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_labels = load_data(\"model-data/epochs-numpy-corrected/train\")\n",
    "# test_data, test_labels = load_data(\"model-data/epochs-numpy-corrected/test\")\n",
    "\n",
    "# # Check shapes of the loaded data\n",
    "# print(f\"Training data shape: {train_data.shape}\")\n",
    "# print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Force CUDA availability check at the start\n",
    "assert torch.cuda.is_available(), \"CUDA is not available. Please run on a machine with a GPU.\"\n",
    "device = torch.device(\"cuda:0\")  # Explicitly use cuda:0\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training data shape: (240, 476, 19, 190)\n",
      "Processed test data shape: (104, 476, 19, 190)\n"
     ]
    }
   ],
   "source": [
    "# Load your raw data\n",
    "train_data, train_labels = load_data(\"model-data/epochs-numpy-corrected/train\")\n",
    "test_data, test_labels = load_data(\"model-data/epochs-numpy-corrected/test\")\n",
    "\n",
    "# Preprocess the EEG data\n",
    "train_data_processed = preprocess_eeg_data(train_data, fs=fs)\n",
    "test_data_processed = preprocess_eeg_data(test_data, fs=fs)\n",
    "\n",
    "\n",
    "# Check shapes of the processed data\n",
    "print(f\"Processed training data shape: {train_data_processed.shape}\")\n",
    "print(f\"Processed test data shape: {test_data_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert processed data to PyTorch tensors - keep on CPU\n",
    "train_data_tensor = torch.tensor(train_data_processed, dtype=torch.float32)\n",
    "test_data_tensor = torch.tensor(test_data_processed, dtype=torch.float32)\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the training labels\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Convert train labels and test labels to PyTorch tensors - keep on CPU\n",
    "train_labels_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "test_labels_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training and testing with GPU optimization\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,  # Speeds up GPU transfer\n",
    "    num_workers=4     # Adjust based on HPC capabilities\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    pin_memory=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n",
      "\n",
      "--- Training EEGNet ---\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [1/25], Train Loss: 3.5995, Train Acc: 29.17%, Val Loss: 1.0977, Val Acc: 31.73%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [2/25], Train Loss: 2.0637, Train Acc: 33.33%, Val Loss: 1.1058, Val Acc: 25.00%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [3/25], Train Loss: 1.3344, Train Acc: 38.75%, Val Loss: 1.1020, Val Acc: 31.73%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [4/25], Train Loss: 1.0179, Train Acc: 42.92%, Val Loss: 1.0940, Val Acc: 43.27%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [5/25], Train Loss: 0.8591, Train Acc: 51.67%, Val Loss: 1.0794, Val Acc: 43.27%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [6/25], Train Loss: 0.8377, Train Acc: 53.75%, Val Loss: 1.0759, Val Acc: 43.27%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [7/25], Train Loss: 0.8670, Train Acc: 49.17%, Val Loss: 1.0925, Val Acc: 45.19%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [8/25], Train Loss: 0.8840, Train Acc: 50.83%, Val Loss: 1.1143, Val Acc: 34.62%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [9/25], Train Loss: 0.8843, Train Acc: 49.58%, Val Loss: 1.0957, Val Acc: 44.23%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [10/25], Train Loss: 0.8293, Train Acc: 51.67%, Val Loss: 1.0956, Val Acc: 36.54%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [11/25], Train Loss: 0.8639, Train Acc: 50.42%, Val Loss: 1.0990, Val Acc: 43.27%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [12/25], Train Loss: 0.8712, Train Acc: 50.42%, Val Loss: 1.1066, Val Acc: 35.58%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [13/25], Train Loss: 0.8826, Train Acc: 50.42%, Val Loss: 1.1046, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [14/25], Train Loss: 0.8584, Train Acc: 53.33%, Val Loss: 1.1216, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [15/25], Train Loss: 0.8340, Train Acc: 50.00%, Val Loss: 1.1226, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [16/25], Train Loss: 0.8495, Train Acc: 47.50%, Val Loss: 1.1686, Val Acc: 36.54%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [17/25], Train Loss: 0.8603, Train Acc: 51.25%, Val Loss: 1.1517, Val Acc: 41.35%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [18/25], Train Loss: 0.8365, Train Acc: 53.75%, Val Loss: 1.1756, Val Acc: 40.38%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [19/25], Train Loss: 0.8404, Train Acc: 53.33%, Val Loss: 1.1711, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [20/25], Train Loss: 0.8342, Train Acc: 53.33%, Val Loss: 1.1836, Val Acc: 40.38%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [21/25], Train Loss: 0.8358, Train Acc: 53.75%, Val Loss: 1.1612, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [22/25], Train Loss: 0.8362, Train Acc: 53.75%, Val Loss: 1.1682, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [23/25], Train Loss: 0.8357, Train Acc: 53.75%, Val Loss: 1.1806, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [24/25], Train Loss: 0.8410, Train Acc: 53.75%, Val Loss: 1.1983, Val Acc: 42.31%\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([16, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([16, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Epoch [25/25], Train Loss: 0.8346, Train Acc: 53.75%, Val Loss: 1.2306, Val Acc: 41.35%\n",
      "Finished Training EEGNet. Total time: 37.78 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create model and ensure it's on CUDA\n",
    "model3 = EEGNet(n_channels=19, n_timesteps=190, num_classes=len(set(train_labels)))\n",
    "model3 = model3.to(device)  # Ensure all parameters are on CUDA\n",
    "\n",
    "# Verify model is on CUDA\n",
    "print(f\"Model is on device: {next(model3.parameters()).device}\")\n",
    "\n",
    "# Loss function\n",
    "criterion3 = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "num_epochs = 25  # Start with 1 epoch for testing\n",
    "train_model(model3, train_loader, test_loader, criterion3, optimizer3, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model's accuracy on the provided data loader.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained PyTorch model to evaluate.\n",
    "        data_loader (DataLoader): DataLoader for the dataset to evaluate on (e.g., test_loader or val_loader).\n",
    "        device (torch.device): The device to run evaluation on (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the dataset (in percentage).\n",
    "               Returns 0.0 if the data_loader is empty or None.\n",
    "    \"\"\"\n",
    "    if data_loader is None or len(data_loader) == 0:\n",
    "        print(\"Warning: Evaluation data loader is empty or None. Returning 0.0 accuracy.\")\n",
    "        return 0.0\n",
    "\n",
    "    model.to(device)  # Ensure model is on the correct device\n",
    "    model.eval()      # Set the model to evaluation mode (disables dropout, uses running means/vars for BatchNorm)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations - crucial for evaluation efficiency and correctness\n",
    "        for inputs, labels in data_loader:\n",
    "            # Move data to the designated device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Check if reshaping is necessary (depending on your model's expected input format)\n",
    "            if inputs.ndimension() == 4:  # If input is in the format (batch_size, channels, time_steps, features)\n",
    "                # Reshape or permute as necessary, for example, (batch_size, 19, 190, 476) -> (batch_size, 19, 476, 190)\n",
    "                inputs = inputs.permute(0, 2, 3, 1)  # Adjust this based on your model's expected input format\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get predictions from the maximum value\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability/logit\n",
    "\n",
    "            # Update total samples and correct predictions count\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate final accuracy\n",
    "    accuracy = 100 * correct_predictions / total_samples\n",
    "    print(f\"Evaluation Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "Evaluation Accuracy: 41.35%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.34615384615385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model3, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def evaluate_and_compare_models(models, model_names, data_loader, device, num_classes):\n",
    "    \"\"\"\n",
    "    Evaluate multiple trained models on the same dataset and plot ROC curves.\n",
    "    \n",
    "    Args:\n",
    "        models (list): List of trained PyTorch models.\n",
    "        model_names (list): List of model names for labeling.\n",
    "        data_loader (DataLoader): DataLoader for validation or test set.\n",
    "        device (torch.device): Device for model execution.\n",
    "        num_classes (int): Total number of output classes.\n",
    "    \n",
    "    Returns:\n",
    "        reports (dict): A dictionary of classification report DataFrames per model.\n",
    "    \"\"\"\n",
    "    reports = {}\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    for model, name in zip(models, model_names):\n",
    "        if data_loader is None:\n",
    "            print(f\"Skipping {name}: data_loader is None.\")\n",
    "            continue\n",
    "        \n",
    "        model.eval()\n",
    "        y_true, y_pred, y_probs = [], [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in data_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                \n",
    "                # Reshape inputs to match model expectations\n",
    "                # Assuming the model expects shape (batch_size, 19, 190, 476)\n",
    "                X_batch = X_batch.permute(0, 2, 3, 1)\n",
    "                \n",
    "                outputs = model(X_batch)\n",
    "                probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "                y_probs.extend(probs)\n",
    "                y_true.extend(y_batch.numpy())\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        # Print Accuracy\n",
    "        acc = accuracy_score(y_true, y_pred) * 100  # Convert to percentage\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"Accuracy: {acc:.2f}%\")\n",
    "        \n",
    "        # Print classification report\n",
    "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        display(report_df[[\"precision\", \"recall\", \"f1-score\", \"support\"]])\n",
    "        reports[name] = report_df\n",
    "        \n",
    "        # Compute ROC Curve (Micro-average for multiclass)\n",
    "        y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "        y_probs = np.array(y_probs)\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_true_bin.ravel(), y_probs.ravel())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
    "    \n",
    "    # ROC Plot settings\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "    plt.title(\"Micro-Averaged ROC Curves\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([32, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([32, 41280])\n",
      "Shape before flattening: torch.Size([8, 16, 172, 15])\n",
      "Shape after flattening: torch.Size([8, 41280])\n",
      "\n",
      "=== EEGNet ===\n",
      "Accuracy: 41.35%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.413462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.247222</td>\n",
       "      <td>0.337374</td>\n",
       "      <td>0.273871</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.287260</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.327166</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.450000  0.800000  0.576000   45.000000\n",
       "1              0.291667  0.212121  0.245614   33.000000\n",
       "2              0.000000  0.000000  0.000000   26.000000\n",
       "accuracy       0.413462  0.413462  0.413462    0.413462\n",
       "macro avg      0.247222  0.337374  0.273871  104.000000\n",
       "weighted avg   0.287260  0.413462  0.327166  104.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up model list and names\n",
    "model_list = [model3]  # Assuming model3 is your trained EEGNet model\n",
    "model_names = [\"EEGNet\"]\n",
    "\n",
    "# Get the number of classes from your labels\n",
    "num_classes_actual = len(set(train_labels))\n",
    "\n",
    "# Use test_loader since you have both train and test loaders\n",
    "data_loader_to_use = test_loader  \n",
    "\n",
    "if data_loader_to_use is None:\n",
    "    raise ValueError(\"No data available for evaluation.\")\n",
    "\n",
    "# Call the evaluation function\n",
    "all_reports = evaluate_and_compare_models(\n",
    "    models=model_list,\n",
    "    model_names=model_names,\n",
    "    data_loader=data_loader_to_use,\n",
    "    device=device,\n",
    "    num_classes=num_classes_actual\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "My Custom Env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
