{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96feecd3-cecb-4c41-ace7-39482b017ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to create new mne-python configuration file:\n",
      "/home/tj2286/.mne/mne-python.json\n",
      "Loading 3219 EEG samples for train...\n",
      "Loaded training data: (3219, 190) features, 3219 labels\n",
      "Training Random Forest model...\n",
      "Training accuracy: 1.0000\n",
      "\n",
      "Evaluating on test_cross data (different subjects)...\n",
      "Loading 873 EEG samples for test_cross...\n",
      "Loaded test_cross data: (873, 190) features, 873 labels\n",
      "\n",
      "===== Test Cross-Subject Results =====\n",
      "Accuracy: 0.4845\n",
      "Precision: 0.5833\n",
      "Recall: 0.4845\n",
      "F1 Score: 0.4556\n",
      "\n",
      "Confusion Matrix:\n",
      "[[206 110   3]\n",
      " [123 180   4]\n",
      " [179  31  37]]\n",
      "\n",
      "Per-class metrics:\n",
      "Class A:\n",
      "  Precision: 0.4055\n",
      "  Recall: 0.6458\n",
      "  F1 Score: 0.4982\n",
      "Class C:\n",
      "  Precision: 0.5607\n",
      "  Recall: 0.5863\n",
      "  F1 Score: 0.5732\n",
      "Class F:\n",
      "  Precision: 0.8409\n",
      "  Recall: 0.1498\n",
      "  F1 Score: 0.2543\n",
      "\n",
      "Evaluating on test_within data (same subjects)...\n",
      "Loading 344 EEG samples for test_within...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import mne\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Ignore RuntimeWarning\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Enable CUDA\n",
    "mne.utils.set_config('MNE_USE_CUDA', 'true')\n",
    "mne.cuda.init_cuda(verbose=False)  # Set to True for debugging\n",
    "\n",
    "def load_eeg_data(file_path):\n",
    "    \"\"\"Load EEG data from EEGLAB file\"\"\"\n",
    "    try:\n",
    "        raw = mne.io.read_raw_eeglab(file_path)\n",
    "        return raw.get_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "class EEGRFDataset:\n",
    "    \"\"\"\n",
    "    Dataset handler for EEG data to be used with Random Forest models.\n",
    "    Loads and preprocesses EEG data from files.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, data_info=None, scaler=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset handler.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): Directory containing the EEG data files\n",
    "            data_info (list): List of dictionaries containing file information\n",
    "                             (if None, will try to load from labels.json)\n",
    "            scaler (StandardScaler): Pre-fitted scaler for feature normalization\n",
    "                                    (if None, a new one will be created and fitted)\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "        # Load data info if not provided\n",
    "        if data_info is None:\n",
    "            with open(os.path.join(data_dir, 'labels.json'), 'r') as f:\n",
    "                self.data_info = json.load(f)\n",
    "        else:\n",
    "            self.data_info = data_info\n",
    "\n",
    "        self.scaler = scaler\n",
    "\n",
    "        # Generate data and labels lists\n",
    "        self.data = [d['file_name'] for d in self.data_info]\n",
    "        self.labels = [0 if d['label'] == 'A' else 1 if d['label'] == 'C' else 2 for d in self.data_info]\n",
    "\n",
    "    def load_data(self, data_type=None):\n",
    "        \"\"\"\n",
    "        Load and preprocess the EEG data.\n",
    "\n",
    "        Args:\n",
    "            data_type (str, optional): Type of data to load (e.g., 'train', 'test_cross', 'test_within')\n",
    "                                      If None, all data will be loaded.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (X, y) where X is the feature matrix and y contains the labels\n",
    "        \"\"\"\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # Filter by data type if specified\n",
    "        if data_type is not None:\n",
    "            filtered_info = [d for d in self.data_info if d['type'] == data_type]\n",
    "        else:\n",
    "            filtered_info = self.data_info\n",
    "\n",
    "        print(f\"Loading {len(filtered_info)} EEG samples for {data_type}...\")\n",
    "\n",
    "        # Load each EEG file\n",
    "        for item in filtered_info:\n",
    "            file_path = os.path.join(self.data_dir, item['file_name'])\n",
    "            label = 0 if item['label'] == 'A' else 1 if item['label'] == 'C' else 2\n",
    "\n",
    "            # Load the EEG data from the file\n",
    "            eeg_data = load_eeg_data(file_path)\n",
    "\n",
    "            if eeg_data is not None:\n",
    "                # Preprocess EEG data for Random Forest\n",
    "                features = self._preprocess_eeg(eeg_data)\n",
    "\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        if len(X) == 0:\n",
    "            raise ValueError(f\"No valid data loaded for {data_type}. Please check file paths and data format.\")\n",
    "\n",
    "        # Create and fit scaler if not provided\n",
    "        if self.scaler is None:\n",
    "            self.scaler = StandardScaler()\n",
    "            X = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            X = self.scaler.transform(X)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def _preprocess_eeg(self, eeg_data):\n",
    "        \"\"\"\n",
    "        Preprocess the EEG data for Random Forest input.\n",
    "\n",
    "        Args:\n",
    "            eeg_data (numpy.ndarray): Raw EEG data\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Preprocessed features\n",
    "        \"\"\"\n",
    "        # Assuming eeg_data shape is (channels, samples) or (samples, channels)\n",
    "        # If data is (samples, channels), transpose it\n",
    "        if eeg_data.shape[0] > eeg_data.shape[1]:\n",
    "            eeg_data = eeg_data.T\n",
    "\n",
    "        num_channels = eeg_data.shape[0]\n",
    "\n",
    "        # Feature extraction\n",
    "        features = []\n",
    "\n",
    "        # Time domain and frequency domain features for Random Forest\n",
    "        for channel in range(num_channels):\n",
    "            channel_data = eeg_data[channel, :]\n",
    "\n",
    "            # Time domain features\n",
    "            features.extend([\n",
    "                np.mean(channel_data),\n",
    "                np.std(channel_data),\n",
    "                np.max(channel_data),\n",
    "                np.min(channel_data),\n",
    "                np.percentile(channel_data, 75) - np.percentile(channel_data, 25)\n",
    "            ])\n",
    "\n",
    "            # Frequency domain features\n",
    "            fft_data = np.abs(np.fft.rfft(channel_data))\n",
    "            # Normalized frequency band powers\n",
    "            total_power = np.sum(fft_data)\n",
    "            features.extend([\n",
    "                np.sum(fft_data[:5]) / total_power,  # Delta\n",
    "                np.sum(fft_data[5:12]) / total_power,  # Theta\n",
    "                np.sum(fft_data[12:30]) / total_power,  # Alpha\n",
    "                np.sum(fft_data[30:80]) / total_power,  # Beta\n",
    "                np.sum(fft_data[80:]) / total_power  # Gamma\n",
    "            ])\n",
    "\n",
    "        return np.array(features)\n",
    "\n",
    "class EEGRF:\n",
    "    \"\"\"\n",
    "    Random Forest model for EEG classification with hyperparameter optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=100, max_depth=None, class_weight=None):\n",
    "        \"\"\"\n",
    "        Initialize the Random Forest model.\n",
    "\n",
    "        Args:\n",
    "            n_estimators (int): Number of trees in the forest\n",
    "            max_depth (int or None): The maximum depth of the trees\n",
    "            class_weight (dict or 'balanced'): Weights associated with classes in the form {class_label: weight}\n",
    "        \"\"\"\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            class_weight=class_weight,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train the Random Forest model.\n",
    "\n",
    "        Args:\n",
    "            X_train (numpy.ndarray): Training features\n",
    "            y_train (numpy.ndarray): Training labels\n",
    "\n",
    "        Returns:\n",
    "            EEGRF: Self for method chaining\n",
    "        \"\"\"\n",
    "        print(\"Training Random Forest model...\")\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        train_pred = self.model.predict(X_train)\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions with the trained model.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): Features\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predictions\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on test data.\n",
    "\n",
    "        Args:\n",
    "            X_test (numpy.ndarray): Test features\n",
    "            y_test (numpy.ndarray): Test labels\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "def print_evaluation_results(results, data_type):\n",
    "    \"\"\"Print detailed evaluation results in a formatted way\"\"\"\n",
    "    print(f\"\\n===== {data_type} Results =====\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {results['f1']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(results['confusion_matrix'])\n",
    "    \n",
    "    # Calculate per-class metrics from confusion matrix\n",
    "    cm = results['confusion_matrix']\n",
    "    classes = ['A', 'C', 'F']\n",
    "    \n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        # True positives: diagonal elements\n",
    "        tp = cm[i, i]\n",
    "        # False positives: sum of column i minus diagonal element\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        # False negatives: sum of row i minus diagonal element\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        # True negatives: sum of all elements minus tp, fp, fn\n",
    "        tn = np.sum(cm) - tp - fp - fn\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"Class {cls}:\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "\n",
    "def main():\n",
    "    data_dir = \"model-data\"\n",
    "    \n",
    "    # Create dataset handler\n",
    "    dataset = EEGRFDataset(data_dir)\n",
    "    \n",
    "    # Load training data\n",
    "    X_train, y_train = dataset.load_data(data_type='train')\n",
    "    print(f\"Loaded training data: {X_train.shape} features, {len(y_train)} labels\")\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    rf_model = EEGRF(n_estimators=100, max_depth=None, class_weight='balanced')\n",
    "    rf_model.train(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on test_cross data\n",
    "    print(\"\\nEvaluating on test_cross data (different subjects)...\")\n",
    "    X_test_cross, y_test_cross = dataset.load_data(data_type='test_cross')\n",
    "    print(f\"Loaded test_cross data: {X_test_cross.shape} features, {len(y_test_cross)} labels\")\n",
    "    \n",
    "    if len(y_test_cross) > 0:\n",
    "        results_cross = rf_model.evaluate(X_test_cross, y_test_cross)\n",
    "        print_evaluation_results(results_cross, \"Test Cross-Subject\")\n",
    "    else:\n",
    "        print(\"No test_cross data available.\")\n",
    "    \n",
    "    # Evaluate on test_within data\n",
    "    print(\"\\nEvaluating on test_within data (same subjects)...\")\n",
    "    X_test_within, y_test_within = dataset.load_data(data_type='test_within')\n",
    "    print(f\"Loaded test_within data: {X_test_within.shape} features, {len(y_test_within)} labels\")\n",
    "    \n",
    "    if len(y_test_within) > 0:\n",
    "        results_within = rf_model.evaluate(X_test_within, y_test_within)\n",
    "        print_evaluation_results(results_within, \"Test Within-Subject\")\n",
    "    else:\n",
    "        print(\"No test_within data available.\")\n",
    "    \n",
    "    # Calculate and print overall metrics (combined test sets)\n",
    "    if len(y_test_cross) > 0 and len(y_test_within) > 0:\n",
    "        print(\"\\nEvaluating on combined test data...\")\n",
    "        X_test_combined = np.vstack([X_test_cross, X_test_within])\n",
    "        y_test_combined = np.concatenate([y_test_cross, y_test_within])\n",
    "        results_combined = rf_model.evaluate(X_test_combined, y_test_combined)\n",
    "        print_evaluation_results(results_combined, \"Combined Test\")\n",
    "    \n",
    "    print(\"\\nRandom Forest evaluation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12380748-4ad5-4d09-a231-f0816b62b334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Custom Env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
